[
  {
    "title": "Natron’s Failure May Not Spell Doom for Sodium-Ion Batteries",
    "link": "https://spectrum.ieee.org/natron-sodium-ion-battery-failure",
    "summary": "Natron Energy , a Santa Clara, California-based sodium-ion battery startup, ceased operation on 3 September due to funding issues. Just a year ago, the company made headlines for its plans to build a first-of-its-kind US $1.4 billion factory in North Carolina to manufacture up to 14 gigawatt-hours of sodium-ion batteries . While experts say Natron’s closure shouldn’t be taken as a harbinger for the rest of the emerging industry in the United States, they acknowledge that the West is behind China, which is leveraging its dominance in lithium-ion batteries to forge ahead on sodium-ion battery manufacturing. In the U.S., sodium-ion startups like Natron, which launched in 2012, tend to rely on goodwill from funders, says K.M. Abraham , a retired research professor at Northeastern University in Boston and CTO of lithium-ion battery consulting firm E-KEM Sciences . This can pose challenges for companies when funding timelines outpace innovations. “Companies aren’t able to make progress quickly enough to keep up with pressure exerted by the investors,” he says. Natron’s Pioneering Prussian Blue Batteries Until recently, Natron was seen as a leader of the pack in the U.S. sodium-ion market. Part of the company’s appeal was its pioneering approach to low-cost electrodes, the conductors at the battery’s positive and negative terminals, which make contact with the non-metallic part of the circuit. The company used Prussian Blue , a pigment found in paints and dyes, to make both the cathode and anode for its three battery systems . In addition to having a low material cost, Prussian Blue’s chemical structure has large pores, helping it facilitate faster ion transfer between the electrodes. Natron was the first in the world to commercialize a sodium-ion battery using Prussian Blue, a real feat considering China’s battery manufacturing might, says Tyler Evans , co-founder and CEO of Mana Battery , a Broomfield, Colorado-based sodium-ion battery cell startup that launched in 2023. “They were doing it in the West, and they were scaling a technology that was relatively low energy density for a very specific market segment,” says Evans about Natron’s products. Mana is another U.S. startup focusing on bringing sodium-ion batteries to market. Nicholas Singstock/Mana That market included grid storage, data center power backups, and electric vehicle charging stations—large-scale stationary applications where attributes like safety and cost rank higher than energy density. Natron’s success in this space, including its plans for the North Carolina factory, prompted questions about whether sodium-ion could emerge as a direct replacement for lithium-ion batteries. United Airlines and Chevron were on the list of Natron’s investors. But Evans says scaling up a low-energy density product while building out manufacturing lines is expensive. “If you think about building a manufacturing facility where you want to produce 10 gigawatt hours of batteries, if your energy density is very low, producing an equivalent number of batteries requires more manufacturing lines,” Evans says. “If you think about building a manufacturing facility where you want to produce a gigawatt-hour of battery manufacturing capacity, if your energy density per battery cell is very low, producing that capacity requires more manufacturing lines,” Evans says, meaning significantly more capital and operational expenditure in an already capital-intensive undertaking. In 2023, Natron’s systems made it to market. The company partnered with Encorp to deploy the industry’s first multi-megawatt class power platform for industrial applications. A year later, in 2024, Natron opened the U.S.’s first commercial scale manufacturing facility in Holland, Michigan to supply data centers with energy storage. The U.S. Department of Energy’s ARPA-E program provided $19.8 million to Natron as part of a $300 million facility upgrade to transition from lithium-ion battery manufacturing to sodium-ion battery manufacturing. That facility shut its doors at the same time as Natron’s California headquarters on 3 September. A request for comment from Natron resulted in an automated message to contact the company’s primary shareholder , Sherwood Partners. Sherwood Partners did not respond to a request for comment. Sodium-Ion vs. Lithium-Ion Battery Costs Adrian Yao is the founder and team lead of Stanford’s STEER initiative , a DOE-funded research program. He’s also an author of a January 2025 paper assessing how sodium-ion batteries measure up to lithium-ion batteries in terms of technology and cost. While he was impressed with Natron’s technology and product, he says that the company may have been ahead of the curve on the data center market niche it had carved out for itself. “Hyperscalers right now, their primary concern is just getting connected and building data centers,” says Yao. “I think timing on that cycle may be early, and it’s unfortunate things don’t always work out.” Natron joins Stanford spin-out Bedrock Materials as the second sodium-ion company to fold this year. Bedrock cited market and innovation challenges for its April closure. “The battery business is very difficult. There are a lot of tombstones,” says Andrew Thomas , president and cofounder of Acculon Energy , a Columbus, Ohio-based startup marketing two battery modules with sodium-ion cells for industrial energy and EVs that travel at low speeds, like golf carts. Unlike Natron, Acculon, which launched in 2022, employs more traditional layered-metal oxides and other sodium chemistries. Thomas says it’s this distinction that makes it hard to draw conclusions about the U.S. sodium-ion battery industry as a whole in light of Natron’s closure. Comparing different sodium-ion chemistries, like Prussian Blue or layered metal oxides, is like comparing apples to oranges. “I don’t think one failure is representative of a country being unable, but we’re at a significant disadvantage given the installed base in China,” Thomas says. China is the dominant player in sodium-ion battery development, with companies like CATL displaying their designs at tech expos. Yuan Zheng/VCG/AP China’s Dominance in Battery Manufacturing China has long dominated the battery industry, and sodium-ion batteries are no exception. Today, China produces more than 75 percent of batteries sold globally, according to the International Energy Agency . On the sodium-ion front, developers like CATL have moved into second-generation batteries, with the April launch of Naxtra, a brand geared toward EV applications. Yao says he’d like to see the U.S. concentrate its focus more on building up its manufacturing prowess to compete with China. “My broader critique of the Western Hemisphere in terms of our thinking and obsession with trying to innovate ourselves out of the problem, is that we focus too much on tech,” Yao says. “We have very little manufacturing experience… Our yield rates are abysmal, and our workforce is not trained.” Founders like Evans and Thomas are optimistic about their prospects as growing demand for grid storage, data centers, and low-cost mobility applications drives the need for applications they say sodium-ion batteries are uniquely equipped to support in terms of temperature range, safety, and cost metrics. When it comes to manufacturing, Mana is taking a page from China’s playbook by partnering with existing manufacturers to scale up production. Evans says there’s an appetite for this kind of partnership in the U.S. right now. “I think it’s a commercialization sweet spot that’s specific to sodium.”",
    "published": "Mon, 06 Oct 2025 17:56:02 +0000",
    "author": "Julia Tilton",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "A Shrinking Workforce Threatens the Future of the Grid",
    "link": "https://spectrum.ieee.org/power-engineering-workforce-gap",
    "summary": "As renewable energy scales up and data centers demand more electricity than ever, the electrical systems that power the modern world face mounting stress. At the heart of this infrastructure are power engineers: technical professionals who design, build, and maintain the power grid. But just as demand for electricity skyrockets, a shortage in talent now threatens to derail the energy sector. According to a recent joint study by consulting firm Kearney and IEEE, the global power sector will need between 450,000 and 1.5 million more engineers by 2030 to build, implement, and operate energy infrastructure. Already, 40 percent of power executives report difficulty hiring skilled workers, citing talent competition and insufficient skills as key barriers. That gap is a major concern for energy leaders. Some say that a talent shortage could threaten to delay critical infrastructure upgrades just when the grid needs to evolve faster than ever. More frequent service disruptions could follow as extreme weather events strain aging grid equipment, and energy demands continue to grow. Hiring bottlenecks could also stall timelines for clean-energy integration, transmission expansions, and nuclear-plant maintenance, jeopardizing both grid reliability and the pace of decarbonization. In response, utilities and engineering firms are exploring new strategies to bolster the pipeline, including partnering with universities, investing in apprenticeship programs, and turning to emerging technologies to offset gaps in the workforce. “Without enough engineers, these critical projects will be delayed, compounding reliability risks and slowing the energy transition at the exact moment when momentum is needed most,” Andre Begosso , a partner at Kearney involved in the study, told IEEE Spectrum . A “Perfect Storm” for a Talent Shortage The root causes of the engineering shortage are mounting. Baby boomers in the workforce are retiring, and not enough young people are stepping in to fill their shoes, leaving utilities and engineering firms with more open roles than people to fill them. “Right now, utility companies are facing a perfect storm of a labor crisis, with an aging workforce and a lack of younger employees to replenish them,” says Kevin Miller , chief technology officer for North America at IFS , a software company with energy-sector clients. Tough working conditions are also pushing engineers out of the field. “Nearly half of all power engineers changed jobs, employers, or left the industry in just the past three years, with burnout and lack of creative problem-solving opportunities among the top reasons,” Begosso says. In nuclear power, where reliability is crucial, Begosso says the churn is even higher: 58 percent of engineers have moved roles. On the education front, the pipeline is drying up. Begosso says that university enrollment in power engineering programs has stagnated as engineering students flock to high-tech fields like data science, software engineering, and AI, which are seen as more exciting and lucrative. Even when companies find new hires, they’re slow to onboard. “Hiring and onboarding these skilled employees takes longer than in other sectors,” says Miller. Manual practices and long training cycles stretch timelines, he says, and when errors occur, supervisors must divert attention away from core operations. Without enough power engineers, substations may not receive the maintenance and upgrades they need. Sirathee Boonpanyarak/Alamy How Engineering Firms Are Managing the Gap At Black & Veatch , one of the largest engineering firms in the United States, early-career recruitment is crucial for filling staffing needs. The company turns 85 to 90 percent of its interns into entry-level hires, and last summer, that rate hit 93 percent, according to Ryan Elbert , executive vice president and global director of engineering and development services at Black & Veatch. He says the firm invests heavily in growing its own talent pool, hiring interns and recent graduates to fill about 10 to 15 percent of their engineering teams. But even with this strategy Black & Veatch isn’t immune. “I think the talent shortage really plays out a lot more at the experienced level,” Elbert says. “Hiring top-tier seasoned engineers is really no small feat.” Smaller firms are especially feeling the heat. With limited resources, they often find themselves in direct competition with industry giants that can offer higher pay and better perks. Heather Eason , CEO of Select Power Systems , a boutique engineering firm, recounts how a junior engineer—hired straight out of college and trained in substation design—was poached by a competitor within six months for just US $5 more an hour. Particularly for younger workers, “money speaks,” Eason says. Many large firms can plan for staffing needs long before a project begins, but smaller firms don’t always have that luxury. Eason says that Select Power typically spends 6 to 9 months filling roles. So when a key engineer left Select for a larger firm, the company had to walk away from a major transmission line project. “I’m not going to be able to put a T-line [transmission line] team together in eight weeks,” she says. Obtaining the credentials needed to become a licensed professional engineer could exacerbate the talent gap. Eason says that becoming a licensed professional engineer requires a bachelor’s degree in electrical engineering, completion of the Engineer-in-Training (EIT) and Professional Engineering (PE) exams, and four years of work experience in between those tests. While engineers don’t need to hold these certifications to be hired, having them on their résumés provides engineers with the credentials employers look for when hiring for better-paying jobs with more responsibility. That lengthy process could deter engineers from taking the exams, potentially stifling their career development, especially for women who may have additional caretaking responsibilities. “I never got my PE registration, and it has definitely limited me,” Eason says. “I didn’t have the ability to just stop being a mom to four kids so I could study for six months for an 8-hour exam.” Participants receive training during the 2025 International Hybrid Power Plants & Systems Workshop in Mariehamn, Åland. Energynautics Tech, Training, and Transfer of Knowledge Rather than chasing an ever-shrinking pool of engineers, some utilities are using technology to get more out of the staff they already have. For instance, IFS deploys augmented reality tools designed to help senior technicians assist their less experienced colleagues in troubleshooting problems in real time. Companies in need of talent are also investing in upskilling initiatives. At Power Academy , a training program for utility workers run by global engineering firm TRC Companies, director of technical services Anna Campbell says demand from utilities and data centers is growing fast. Those clients require expertise in protection, controls, and substation engineering—skills learned as part of the Power Academy training program. “There simply isn’t enough talent to meet the need,” Campbell told Spectrum . In the United Kingdom, Excitation & Engineering Services (EES)—whose clients include ConocoPhillips, General Electric, and Siemens—has structured its graduate recruitment program to ensure young engineers work alongside seasoned employees from day one. “It shortens the learning curve but, most importantly, it passes on that knowledge from senior engineers while it’s still available,” EES director Ryan Kavanagh says. Meanwhile, programs such as the education division of Bentley Systems , in Exton, Pa., offer university students free access to engineering software, online courses, and global competitions that prepare them for engineering jobs in the energy sector. “The more we can embed innovation deeper into education, the faster we can deliver on sustainable, resilient infrastructure projects,” says Chris Bradshaw , chief sustainability and education officer at Bentley, which is an infrastructure engineering software firm. Looking ahead, university initiatives that encourage engineering students to pursue jobs in the energy sector, combined with the use of technologies like generative AI and cultural shifts, mark steps toward easing the talent crunch. But the clock is ticking for utilities and engineering firms to address the talent gap before it’s too late. “If the gap persists, the industry simply won’t be able to deliver on its potential,” says Begosso. “The strength of the energy workforce will go a long way in determining how competitive and reliable the power sector, and the economy it underpins, can be in the next decade.”",
    "published": "Mon, 06 Oct 2025 12:00:06 +0000",
    "author": "Aaron Mok",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "The Future of the Grid: Simulation-Driven Optimization",
    "link": "https://spectrum.ieee.org/multiphysics-simulation-power-grid",
    "summary": "This is a sponsored article brought to you by COMSOL . Simulation software is useful in the analysis of new designs for improving power grid resilience, ensuring efficient and reliable power distribution, and developing components that integrate alternative energy sources, such as nuclear fusion and renewables. The ability to simulate multiple physical phenomena in a unified modeling environment gives engineers a deeper understanding of how different components of the grid interact with and affect each other. For example, when designing the various components of grid infrastructure, such as transformers and transmission lines, multiphysics electromagnetic field analysis is essential for ensuring the safety of the surrounding individuals and environment. Understanding thermal behavior, another phenomenon involving multiple physics, is equally necessary for the design of grid components where heat dissipation and thermal stresses can significantly affect performance and lifespan. Structural and acoustics simulation, meanwhile, is used to predict and mitigate issues like transformer vibration and noise — an important practice for ensuring the longevity and reliability of grid components. Multiphysics simulation provides critical insight into the complex interactions at play within power grid components, enabling engineers to virtually test and optimize future grid designs. Electric breakdown and corona discharge analyses are particularly vital for high-voltage transmission lines, as such phenomena can compromise the performance of their insulation systems. Simulation allows development teams to predict where such events are likely to happen, enhancing the design of insulators and other components where the goal is to minimize energy loss and material degradation. As a real-world example, one leading manufacturer uses the COMSOL Multiphysics® simulation software software to develop magnetic couplings, a noncontact alternative to mechanical transmission that enables power transfer without the inherent friction-based limitations of continual contact. While the advantage of friction-free power transmission means that magnetic couplings have found applications in a broad range of technologies, including offshore wind turbines, these systems must be developed carefully to avoid degradation. By employing highly nonlinear hysteresis curves and applying its own material temperature dependences for magnetic loading, the manufacturer’s development team has successfully used multiphysics simulation to help prevent the permanent magnets from reaching critical temperatures, which can cause irreversible demagnetization and compromise the reliability of the designs. Additionally, due to the diverse nature of use cases for magnetic couplings, the company’s design engineers must be able to interchange shapes and materials of magnets to meet customer requirements without building costly and time-consuming prototypes — rendering multiphysics simulation a powerful approach for characterizing configurations, providing virtual prototypes of their designs, and ultimately reducing the price for customers while remaining vigilant on fine details. These examples show just a few of the ways that coupling multiple interacting physics within a single model can lead to successful simulation of real-world phenomena and thereby provide insights into current and future designs. Lightning strikes a tower’s shielded wires. The induced voltage on the three-phase conductors is computed using electromagnetic field analysis. COMSOL Improving Reliability with Digital Twins & Simulation Apps Engineering teams can also use simulation technology to create more efficient, effective, and sustainable power grids by creating digital twins. A digital twin contains a high-fidelity description of a physical product, device, or process — from the microscopic to the macroscopic level — that closely mirrors its real counterpart . For every application, the digital twin is continuously receiving information, ensuring an up-to-date and accurate representation. With this technology, grid operators and their equipment suppliers can predict which components are most likely to fail, enabling them to schedule maintenance and replacement more efficiently and thereby improving grid reliability. Digital twins can be made for equipment ranging from power sources including solar cells and wind turbines to power distribution systems and battery energy storage. An offshore wind farm where lightning strikes one of the turbine blades. The electric field on the turbine towers, seawater, and seabed is shown. COMSOL The most recent modeling and simulation technology provides power and energy companies with tools for creating digital twins in the form of standalone simulation apps, which significantly increases the number of users who have access to advanced simulation technology. By including only relevant functionality in a standalone simulation app, colleagues with no modeling and simulation experience can utilize this technology without needing guidance from the modeling specialist. Furthermore, the use of data-driven surrogate models in simulation apps enables near-instantaneous evaluation of what would otherwise be time-consuming simulations — which means that simulation technology can now be used in a real-world setting. Digital twins, in the form of standalone apps, bring the power of simulation to the field, where grid operators can utilize real-time performance information to ensure grid reliability. For instance, one organization that works with local power companies to analyze equipment maintenance and failure built a custom app based on a multiphysics model it had developed to predict cable faults and improve troubleshooting efficiency. While engineers have been utilizing simulation in labs for decades, cable failure occurs in the field, and onsite troubleshooting personnel are responsible for assessing these failure conditions. With this in mind, an engineer at the organization developed the simulation app using the Application Builder in COMSOL Multiphysics ®. Temperature distribution in a battery energy storage system (BESS). COMSOL The app features relevant parameters that troubleshooting personnel with no prior simulation experience can easily modify. Field technicians enter cable data and select the type of fault, which modifies the multiphysics model in real time, allowing the app to evaluate and output the data necessary to understand the condition that led to the fault. The app then produces a reported potential and electric field, which leads the technicians to an informed decision regarding whether they need to replace or repair the cable. Following the app’s successful deployment, the engineer who developed it stated, “The simulation app plays a key role in cable maintenance. It makes the work of our field technicians more efficient by empowering them to confidently assess and repair faults.” Routine physical tests of grid equipment cannot fully reflect conditions or determine failure types in many situations, as a large number of complex factors must be considered, such as cable structure and material, impurities in the cable, voltage fluctuation, and operating conditions and environments. As a result, simulation has proven to be indispensable in many cases for collecting accurate cable health assessments — and now in the form of custom apps, it is more accessible than ever. Generating Nuclear Solutions Simulation has also been heavily integrated into the design process of various components related to the nuclear industry. For example, simulation was used to help design generator circuit breakers (GCBs) for nuclear power plants. GCBs must be reliable and able to maintain performance even after long periods of inactivity. The COMSOL Multiphysics ® software can be used to improve the current-carrying capacity of the GCBs, which can offer protection from current surges and provide dependable electricity generation. The design of nuclear fusion machines like tokamaks has also benefitted from the use of simulation. These devices must be able to withstand high heat fluxes and plasma disruptions. COMSOL Multiphysics ® has been used to help engineers predict the effects of these problems and come up with design solutions, such as adding a structural support system that can help reduce stress and survive challenging conditions. Engineering the Grid of Tomorrow The development of next-generation power grid systems is a complex and dynamic process that requires safe, reliable, and affordable testing. Multiphysics simulation technology can play a major role in future innovations for this industry, enabling engineers to anticipate and analyze the complex interactions happening inside these devices while building upon the existing infrastructure to address the demands of modern-day consumption. COMSOL Multiphysics is a registered trademark of COMSOL AB.",
    "published": "Mon, 06 Oct 2025 10:00:05 +0000",
    "author": "Bjorn Sjodin",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Where Will Taiwan Get Energy After Its Failed Nuclear Referendum?",
    "link": "https://spectrum.ieee.org/nuclear-energy-taiwan-maanshan-plant",
    "summary": "Taiwan failed to pass an August referendum on whether or not a nuclear plant should be restarted, if it were deemed safe to operate. While the more than 4 million votes for “yes” outnumbered the more than 1.5 million “no” votes, the number of affirmative votes failed to surpass the 25 percent threshold of eligible voters also required for the referendum to pass. As a result, Taiwan remains on the nuclear-free path it has followed since the shutdown of the nuclear plant in question, Maanshan Nuclear Power Plant , in southern Taiwan on 17 May, fulfilling a 2016 government pledge made as a result of Japan’s 2011 Fukushima disaster . However, high-tech industries, including semiconductor manufacturing, AI data centers, and AI infrastructure operators, will continue fueling electricity demand. The question remains as to whether or not Taiwan can deliver reliable clean power to support the growth of these industries amid Chinese geopolitical pressure—and without nuclear energy . Taiwan’s Nuclear Energy Debate Taiwan’s energy landscape remains complex. Nuclear power, developed since the 1970s, has seen older reactors retired since 2018 . Taiwan imports 95 percent of its energy and has a growing reliance on natural gas. But it also aims to reduce carbon emissions, improve grid reliability, and expand its energy storage options. “Without energy, there’s no industrial growth…and nuclear is an excellent option,” Nvidia CEO Jensen Huang said during a prereferendum visit to Taipei on 22 August. He met with key players in high-tech supply chains, including Taiwan Semiconductor Manufacturing Co. (TSMC), the world’s largest chip foundry producing advanced chips for smartphones, high-performance computing, and AI applications. It was not Huang’s first time advocating for nuclear energy. During Computex Taipei in May he said , “We need energy from any single source: wind, solar, nuclear. Taiwan should absolutely invest in nuclear, and it shouldn’t be a stigma to have energy.” Nvidia has been expanding in Taiwan, partnering with Foxconn and the government to build a 10,000-Blackwell GPU AI training and supercomputing facility in the south, opening a larger Taipei office, and collaborating with Taiwanese companies such as TSMC to build an AI infrastructure ecosystem. Taiwan president Lai Ching-te promised to honor the referendum result while focusing on diverse energy sources. He said Taiwan might consider advanced nuclear options if technology improves, waste decreases, and public support grows. In late August, the government approved a draft piece of legislation, the AI Basic Act , designed to create a supportive environment for AI development and use. The draft emphasizes the government’s role in promoting AI research, applications, and infrastructure. Meanwhile, the newly reshuffled Cabinet is under pressure by industry and the broader public to maintain energy security. In mid-September, newly appointed Minister of Economic Affairs Ming-hsin Kung emphasized that Taiwan is a global hub for chips and technology, shaping strategies for the next 10 to 20 years. Taiwan’s Renewable Energy Goals Kung stressed that businesses require both stable power supply and green energy to meet commitments to 100 percent renewable energy from global corporate initiative RE110 . He said the new Cabinet will continue focusing on renewable energy while adjusting rollout speed. The goal is to lift renewables to 20 percent of Taiwan’s power supply by the end of 2026—a challenging target critical in keeping Taiwan competitive in global supply chains. He estimated renewable energy will account for around 15 percent of power generation by the end of 2025, up from 11.9 percent in 2024 . A wind turbine and its solar power system are part of the Taipower Exhibit Center in Pingtung, in southern Taiwan on 29 April 2025. I-Hwa Cheng/AFP/Getty Images For solar, Kung pledged to strengthen existing projects, resolve land-use conflicts with fish farms in solar-fishery initiatives , and replace older solar panels with newer ones that produce twice as much energy. Offshore wind construction will be accelerated, and a trial program for floating wind turbines will resume. Taiwan will also actively develop other green energy sources, such as geothermal and hydrogen. On nuclear, Kung reaffirmed Taiwan’s nuclear-free path but left open the possibility of adopting advanced technologies like small modular reactors . Guidelines for evaluating potential restarts of existing plants will be released by the end of October. The first step will see the Taiwan Power Co. (Taipower) conducting assessments of all three halted nuclear plants, with initial results due next year . Maanshan, which began commercial operations in 1984, is regarded as the most likely to pass the safety self-assessments, which will focus on the ability to maintain aging equipment and upgrade earthquake resilience. In a report released on 26 September, Taiwan’s Energy Administration projects electricity demand to grow 1.7 percent annually from 2025 to 2034. The forecast factors in expansions to Taiwan’s semiconductor industry, investments in AI development, and expected energy savings. To meet rising power demand, the government currently plans to boost natural-gas generation while phasing out large nuclear, coal, and oil plants. Net additions of 12.2 gigawatts in gas-fired capacity are expected by 2034 . Semiconductor Industry Concerns But high-tech industries express concern. In early September, at Semicon Taiwan, Charles Lee , the managing director of Topco Group, a major semiconductor supplier, told IEEE Spectrum that manufacturers worry about grid stability as AI and semiconductor growth accelerates. “Highly polluting coal-fired plants are no longer an option, so we will rely more on liquefied natural gas and less-stable renewables. If nuclear plants could be restarted, I would personally welcome it,” Lee says. Meanwhile, a memory manufacturing director, who spoke on condition of anonymity because he isn’t authorized by his company to speak to the media, told Spectrum that Taiwan’s economy is still manufacturing-driven. “We’re concerned about the low efficiency of green energy. We’ve also noticed a trend abroad, with countries resuming nuclear plant construction,” he says. In a televised debate ahead of the August referendum, Tzu-Hsien Tung, chairman of Pegatron Corp., voiced support for restarting nuclear power plants. He warned that if Taiwan continues to rely on carbon-heavy electricity, local firms could face steep carbon taxes overseas, undermining their global competitiveness. Visitors view AI server samples at the Zhen Ding Tech Group booth during the Semicon Taiwan exhibition in Taipei on 10 September 2025. I-Hwa Cheng/AFP/Getty Images As Taiwanese society debated whether to restart nuclear power plants, some Taiwanese energy experts, including Tze-Luen Lin, deputy executive director of the Taiwanese government’s Office of Energy and Carbon Reduction and a political science professor at National Taiwan University, have called for fresh approaches to Taiwan’s energy resilience amid ongoing Chinese threats, echoing to notions brought by nongovernmental organizations and think thanks, such as the U.S.-based Center for Climate and Security , that a clean-energy transition can strengthen national security. At the Society for Environmental Economics and Policy Studies conference in Japan on 21 September, Lin highlighted that renewable energy is central to both energy and national security. He emphasized, “Energy resilience can only be strengthened through decentralized, locally sourced renewables, combined with microgrids and energy storage,” and warned that large, centralized power plants are easier targets for attack. Commenting on Taiwan’s possible nuclear options, Jusen Asuka , a professor at Tohoku University and chair of the session in the conference, cautioned that small modular reactors remain immature and costly, and investing heavily in them could slow renewable-energy development.",
    "published": "Thu, 02 Oct 2025 17:00:05 +0000",
    "author": "Yu-Tzu Chiu",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "The Story of Engineering Is the Story of Scale",
    "link": "https://spectrum.ieee.org/engineering-scale",
    "summary": "Engineers are masters of scale . They harness energy from the sun, wind, rivers, atoms, and ores. They manipulate electrons, photons, and crystals to compute and communicate. They devise instruments that detect perturbations in the fabric of space-time . And they grapple with challenges—anticipated or not—that are presented by the scale of the problem they are trying to solve. The articles in this issue describe engineers who think about, interact with, and create things at very precise and often mind-boggling scales. They took the point-contact transistor and scaled it over the course of decades into a product manufactured in almost unimaginably large quantities ( 13 sextillion, or 13,000,000,000,000,000,000,000, between 1947 and 2018, by one estimate ) and involving one of the most complex, yet crazily efficient workflows on the planet . They’re sequencing the genomes of 1.8 million species . They’re modeling and mitigating a potential catastrophe—the Kessler syndrome—that threatens to decimate satellites in low Earth orbit [p. 58]. Everywhere you look, engineering ingenuity is pushing against the limits of scale. That ingenuity extends to creating scales for what has yet to be measured. How will we know when AI has achieved human-level general intelligence ? How do we precisely measure the absence of matter in a vacuum ? Then there are the complexities of scaling a technology for mass adoption. Why, for example, have some humanoid robot makers announced overly optimistic deployment targets and boosted production capacity well ahead of specific humanoid robot safety standards, high reliability, decent battery life, or demand for hordes of humanoids ? And how can onshore wind turbines continue to scale up unless there’s a proven way to transport them ? “Infographics let readers grasp at a glance what would take paragraphs of explanation.” —Eliza Strickland In this issue, our editors and artists flex their data-visualization powers through compelling infographics, to help readers appreciate the scale of hundreds of gigatonnes of carbon dioxide and the immense interstellar distances we could traverse with a swarm of tiny, laser-powered space kites. “While we wanted every article to include some visual element, a few topics called for special treatment. You could tell the story of carbon capture or interstellar travel in words, but the real impact comes when you see the gaps, the scales, the leaps involved,” says Senior Editor Eliza Strickland, who curated this issue. “Infographics let readers grasp at a glance what would take paragraphs of explanation, whether it’s the ballooning demand for AI or the long journey from raw quartz to finished computer chips.” Several of these infographics, as well as the cover, were created by renowned graphic designer Carl De Torres, owner of Optics Lab. We also commissioned an essay by the nature writer Paul Bogard, who approached his topic from the human scale. Who among us has not gazed at the stars and marveled at how our eyes are absorbing light that traveled thousands of years to reach us? Bogard ventured to Chile to see how light pollution is encroaching on astronomy and changing our sense of place in the universe , perhaps irrevocably. We hope this issue sparks wonder, and conveys our appreciation for the people who measure the unmeasurable, build the unbuildable, and solve the unsolvable.",
    "published": "Thu, 02 Oct 2025 16:00:03 +0000",
    "author": "Harry Goldstein",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "11 Oddball Technology Records You Probably Didn’t Know",
    "link": "https://spectrum.ieee.org/11-oddball-technology-records-you-probably-didnt-know",
    "summary": "This article is part of The Scale Issue . Longest Continuously Operating Electronic Computer Voyager 1 and its twin space probe , both launched by NASA in 1977, were the first human-made objects to reach interstellar space. But that’s not the only record the spacecraft hold. Voyager 2’s Computer Command System has not been turned off since it first booted up about 48 years ago, making it the longest continuously operating electronic computer. Quietest Place on Earth Can you hear your own heartbeat? For most of us, the answer is no—unless you’re standing in Orfield Laboratories’ anechoic chamber, in which case, you might be able to hear the blood rushing through your veins and the sound of your own blinking, too. The chamber in Minneapolis holds the title for quietest place on earth, with a background noise reading of –24.9 A-weighted decibels—meaning that the ambient sound is far below the threshold of human hearing. Longest-Lasting Battery An experimental electric bell at the University of Oxford, in England, has been ringing nearly continuously for 185 years. Powered by two dry piles—an early type of battery—connected in series, the bell has rung more than 10 billion times since it was set up in 1840. Its ringing, however, is now barely audible beneath the glass bell jar protecting the experiment. Fastest Typing Using Brain Signals For people with certain neurodegenerative conditions that impact muscle control, communication can be difficult. Brain–computer interfaces offer a solution by directly translating brain waves to text. But until recently, that translation has been slow. In 2022, researchers at the University of California, San Francisco, set the record for the fastest communication via brain signals: 78 words per minute. Best-Selling Consumer Electronics Certain consumer electronics, like the iPhone, seem ubiquitous. Over 18 years and about as many generations, more than 2.3 billion Apple smartphones have been sold. But when you break it down to individual models, which devices have been the biggest success? See how some particularly popular devices compare. Strongest Magnetic Field on Earth At least among magnets that don’t explode from their own field strength, the U.S. National High Magnetic Field Laboratory’s Pulsed Field Facility holds the record for strongest magnetic field on earth. The 100-Tesla field, which is about 2 million times as strong as Earth’s magnetic field, can be turned on for 15 milliseconds just once an hour. Biggest Teatime Electricity Spike Brits love their tea. That’s why the United Kingdom’s National Grid engineers have to manage surges in energy use during popular broadcast events, when many viewers put their kettles on simultaneously. The biggest spike occurred during the 1990 World Cup semifinal. Just after England lost the game-deciding penalty shootout, demand surged by 2,800 megawatts, equivalent to the electricity used by approximately 1.1 million kettles. Strongest Robotic Arm In March, Rise Robotics celebrated the Beltdraulic SuperJammer Arm ’s setting of the Guinness World Record for Strongest Robotic Arm Prototype. A collaboration between Rise and the U.S. Air Force, the arm lifted an astonishing 3,182 kilograms, about the weight of an adult female African elephant. Unlike other heavy-lifting machines, the robot uses no hydraulics, only electric power, and it improves efficiency by generating electricity when it’s lowering a load. Smallest Pacemaker Implanting most pacemakers requires invasive surgeries. But a group of researchers at Northwestern University, in Evanston, Ill., has developed a device that can be implanted through the tip of a syringe. Measuring 3.5 millimeters in its largest dimension and suited for newborns with heart defects, the pacemaker—which is designed for patients who need only temporary pacing—safely dissolves in the body after it has done its job. Fastest Data Transfer Earlier this year, a team from the National Institute of Information and Communications Technology and Sumitomo Electric, in Japan, blasted a record 1.02 million billion bits (petabits) across 1,808 kilometers in one second, or 1.86 exabits per second-kilometer. At that rate, in one second, you could send everything everyone in the world watched on Netflix in the first half of this year from Tokyo to Shanghai 4,000 times. A special 19-core optical fiber made it possible. Fastest EV Charging The Chinese automaker BYD used a new fast-charging system that peaked at 1,002 kilowatts and added 421 kilometers of range to a Han L sedan in under five minutes. That’s about 84 kilometers per minute. Among the key innovations behind the feat: 1,500-volt silicon carbide transistors and lithium iron phosphate batteries with half the internal resistance of their predecessors.",
    "published": "Thu, 02 Oct 2025 14:00:04 +0000",
    "author": "Gwendolyn Rak",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "The NEC-Approved Solution That’s Changing How Fleets Approach EV Charging",
    "link": "https://content.knowledgehub.wiley.com/electrify-faster-spend-less-why-fleet-managers-are-turning-to-automated-load-management/",
    "summary": "Maximize existing grid capacity and avoid costly upgrades. Learn how Automated Load Management enables faster, more affordable fleet electrification . Download the free technical guide. Download this free whitepaper now!",
    "published": "Thu, 02 Oct 2025 11:00:04 +0000",
    "author": "The Mobility House",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "AI Expands the Search for New Battery Materials",
    "link": "https://spectrum.ieee.org/ai-battery-material",
    "summary": "When Microsoft researchers in 2023 identified a new kind of material that could dramatically reduce the amount of lithium needed in rechargeable batteries, it felt like combing through a haystack in record time. That’s because their discovery began as 32 million possibilities and, with the help of artificial intelligence, produced a promising candidate within 80 hours. Now researchers at the Pacific Northwest National Laboratory plan to synthesize and test the novel material, Na x Li 3−x YCl 6 , in a battery setup. It’s one of several AI-generated battery chemistries making its way to the real world. Microsoft’s experiment started when the researchers wanted to demonstrate how AI could tackle the needle-in-a-haystack problem of finding useful new materials and chemicals . They decided to seek new candidates for a rechargeable battery’s electrolyte, because a better electrolyte could make batteries safer while simultaneously improving performance, says Nathan Baker , project leader at Microsoft for Azure Quantum Elements , a program to accelerate chemistry and materials research through Microsoft’s advanced computing and AI platforms. “Our goal was to take one of these AI models and show the promise of accelerating scientific discovery—sifting through 32.5 million materials candidates and showing that we could do it in a matter of hours, not years,” Baker says. Their model, called the M3GNet framework, accelerated simulations of molecular dynamics to evaluate properties of the materials such as atomic diffusivity. First, the Microsoft researchers asked the model to drop new chemical elements into known crystalline structures in nature and determine which resulting molecules would be stable, a step that cut the 32 million starting candidates down to half a million. AI then screened those materials based on the necessary chemical abilities to make a battery work, which chopped the pool to just 800. From there, traditional computing and old-fashioned human expertise identified the novel material that could function within a battery and use 70 percent less lithium than the rechargeable batteries in commercial use today. AI’s Role in Next-Gen Battery Design The Microsoft team isn’t alone. Around the world, researchers are busy trying to develop next-generation designs to replace or improve lithium-ion batteries, which use large quantities of rare, expensive, and difficult-to-acquire elements . New battery designs could use more abundant materials, reduce the fire danger from lithium-based liquid electrolytes, and pack more energy into a smaller space. The chemistries to do this are waiting out there to be discovered, and increasingly, researchers are harnessing AI and machine learning to do the work of sorting through the mountain of data. “We are teaching AI how to be a materials scientist,” says Dibakar Datta , associate professor at the New Jersey Institute of Technology, who published a study in August that used AI to identify five candidate materials for batteries that would outperform Li-ion. Datta’s team is working on the multivalent battery: one that employs multivalent ions that can carry multiple charge levels as opposed to the single charge carried by a lithium battery. This would give the battery a greater energy storage capacity, but it also means working with larger ions from elements higher on the periodic table, like magnesium and calcium. Those larger ions won’t necessarily fit into existing battery designs without cracking or breaking the elements, Datta says. His new study used what he calls a crystal diffusion variational autoencoder (CDVAE) that could propose new materials, and a large language model that could find materials that would be the most stable in the real world. From a pool of millions of possibilities, the approach found five porous materials of the right size that could do the job. Guiding an AI model on its hunt through the nearly infinite space of possible materials is the tipping point in this field. The key to using it as a research partner is to find a happy medium between a model that works fast and a model that delivers perfectly accurate results, says Austin Sendek , professor at Stanford University who has developed algorithms to help AI discover new battery materials. “You have to traverse both breadth and depth,” says Sendek. Depth, because designing these things takes a lot of deep scientific knowledge about properties, engineering, and chemistry, and breadth, because you have to apply that knowledge across an infinite chemical space, he says. “That’s where the promise of AI comes in.” AI Battery Technology Search at IBM Researchers at IBM have taken an AI-driven approach to identify new electrolyte candidates , which involved identifying chemical formulations with far higher ionic conductivity than the lithium salts used in current batteries. A typical electrolyte can contain six to eight ingredients including salts, solvents, and additives, and it’s nearly impossible to consider all the combinations without AI. To whittle down the field, the IBM team developed chemical-foundation models trained on billions of molecules. “They capture the basic language of chemistry,” says Young-Hye Na , principal research staff member at IBM Research. Her team then trains those models with battery-related data so the AI can predict important properties for battery applications on scales from individual molecules all the way up to a whole device. Na described the work in a paper published in August in NPJ Computational Materials . Because the work investigates new combinations of existing materials rather than using AI to invent exotic new materials, its potential to help build the battery of tomorrow is that much more promising, Na says. The IBM team is now collaborating with an undisclosed EV manufacturer to design high-performance electrolytes for high-voltage batteries. IBM’s use of AI for batteries isn’t limited to the hunt for promising materials. Typically, when AI reveals a promising new material, the next step is for experimentalists to synthesize the stuff, experiment with it in the lab, and one day to test it in a real device. Machine learning (ML) will aid researchers in this testing step, too. IBM is testing the real-world viability of new battery setups by building their digital twins —virtual models that allow the researchers to predict how a particular battery chemistry would degrade over a lifetime of countless power cycles. The model, developed in collaboration with battery startup Sphere Energy , can predict a battery’s long-term behavior in as few as 50 power cycles modeled on the digital twin, says Teodoro Laino , distinguished research staff member at IBM Research. Quantum-Computing Batteries The next phase of AI battery research is quantum . As Microsoft and IBM push toward the potential of quantum computers, both see its promise to model complex chemistry with no shortcuts or compromises. Na says that while current AI is a crucial tool for investigating battery chemistry, the next step—modeling whole EV battery packs, for example, and taking into consideration all the variables they encounter in the real world—would require the power of quantum computing. As Baker puts it: “We know classical computers have problems generating accurate answers for complex substances, complex molecules, complex materials. So our goal right now is actually to change the way the data is generated by bringing quantum into the loop so that we have higher accuracy data for training ML models.” This article was updated on 2 October 2025.",
    "published": "Wed, 01 Oct 2025 14:00:04 +0000",
    "author": "Andrew Moseman",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Electric Boats Drive New England Aquaculture",
    "link": "https://spectrum.ieee.org/electric-boats-aquaculture",
    "summary": "This article was originally published by Canary Media . At a dock along the banks of the Cousins River, Chad Strater loaded up his small aluminum workboat with power tools and a winch. Strater, who owns a marine construction business, was setting out to tinker with floating equipment at a nearby oyster farm. On the quiet morning in August, with the sun already beating down hard, his vessel whirred to life, only without the usual growl of an oil-guzzling motor. The boat is all electric. Just north of where the Cousins River meets Casco Bay, Willy Leathers was powering up his own electric watercraft, which had its first outing in July. Leathers uses his 28 -foot (8.5-meter) boat for cultivating oysters at Maine Ocean Farms , where roughly 3 million of the animals grow in dozens of floating cages. Both Strater and Leathers said they switched to electric workboats for several reasons. Their new watercraft are a cleaner alternative to the smelly, polluting petroleum-powered vessels that dominate Maine’s 3 , 500 miles (5,633 kilometers) of coastline. Electric propulsion is also significantly quieter than a gas or diesel motor. For Leathers, whose 10 -acre (4-hectare) sea farm is a significant presence in the cove where he operates, the swap is about being a good neighbor to the shoreside community. “ It’s an innovation born from necessity for us,” said Strater about his electric boat, which he docks each night at the Sea Meadow Marine Foundation , the nonprofit boatyard and aquaculture innovation hub he runs with several other small business owners. “[The boat] really works well for what we do with it, and we’re letting farmers use it to see how it could work for them.” The Rise of Electric Boats Battery-powered vessels are starting to catch on in the United States and worldwide as companies and maritime authorities work to reduce emissions and improve the experience of cruising waterways. The technology ranges from small outboard motors on workboats and recreational watercraft to powerful inboard systems on ferries, tugboats , and supply vessels for offshore wind farms and oil rigs. In recent decades, Norway, with its extensive coastline and ample government funding, has spearheaded the transition globally. China, which is both the world’s largest shipbuilder and battery manufacturer, has rapidly deployed hundreds of battery-powered vessels over the last several years. Falling battery costs, better technology, and stricter environmental rules are compelling some vessel owners to install partial or fully electric systems, primarily for watercraft that operate near the shore or on fixed routes. For commercial fishing in particular, customers are helping to drive the push to clean up. “ Everyone’s more concerned now with where their food comes from, and we’ve seen that [consumers] are looking for that complete sustainable supply chain,” said Ed Schwarz, the head of marine solutions sales in North America for Siemens Energy, which has built electric propulsion systems for U.S. ferries . Maine Ocean Farms founders Eric Oransky [left] and Willy Leathers switched to an electric workboat in July 2025. Brendan Bullock Electrification has only very recently come to the U.S. aquaculture sector. In Maine, the small but fast-growing segment includes nearly 200 farms for shellfish, fin fish, and edible seaweed. Strater and Leathers are among the first in their business to trade gas motors for electric propulsion—a switch they say they’re hoping to accelerate. Oil-guzzling motors are among the largest sources of greenhouse gas emissions for the state’s multibillion-dollar seafood sector. Still, electrifying commercial watercraft can be a difficult course to navigate , given the higher up-front costs of electric motors and the lack of charging infrastructure—and grid infrastructure in general—in rural waterfront communities. Early adopters like Strater and Leathers said they hope the experiences gained from their demonstrations can help pave the way for decarbonizing Maine’s blue economy. With the help of the Island Institute , a Maine-based nonprofit that works on marine-related energy transitions, Leathers is collecting performance data from his vessel to share more broadly with the industry. “ People say it looks cool and shiny and looks like it operates great,” Lia Morris, the Island Institute’s senior community development officer, said of electric boats. “ But we really want to be able to prove out the [business] case.” Electric boats can cost between 20 percent and 30 percent more than a gas- or diesel-powered vessel of a comparable size. However, owners can save on maintenance and fuel over the long term, Strater’s business partner Nick Planson said. “ The high-level math that we’ve come up with” is a financial break-even point of “ about four to five years, and then over a 10 -year time span, you’re definitely coming out way ahead based on the vastly reduced maintenance cost, replacement cost of failed equipment, and fuel costs,” said Planson. Battery-Powered Workboats Lack Charging Infrastructure But the initial price tag presents a significant hurdle. Strater and Planson’s sleekly designed, no-frills watercraft cost US $ 100 , 000 to build and outfit with a single electric outboard motor. Leathers’s boat, called Heron, cost about four times as much. It has two electric outboards and a ramp for unloading and hauling more than 10 , 000 oysters at a time from the sea farm to distributors waiting on the dock. Its hull is also equipped with a small cabin and toilet. Both operations relied on grant funding to defray the expense of going electric. For their part, Strater and Planson used about $ 50 , 000 from a larger U.S. Department of Agriculture small business grant they got in 2024 to establish a use case for electric workboats in the aquaculture industry. Leathers’s business, Maine Ocean Farms, was included on a collaborative $ 500 , 000 U.S. Department of Energy (DOE) grant last year that earmarked about $ 289 , 000 for boat building and propulsion systems, in addition to other funds for charging infrastructure and data collection. The prospects for funding future projects are now much murkier under the Trump administration, maritime policy experts say. The DOE ’s Office of Energy Efficiency and Renewable Energy, which awarded the money to Maine Ocean Farms and its partners, is facing significant budget cuts in the next fiscal year. The GOP-backed spending law that passed in July rescinded some unobligated grant funding for cleaning up marine diesel engines. While other programs were spared, it’s unclear whether the current Congress will approve new funding for initiatives ranging from electrifying huge urban ports to deploying low-emissions ferries in rural communities. “ We can go really fast for a short distance. We can go really slow for a long distance, and it works for what we do with it,” says Strater. But federal grants aren’t the only way to address the higher cost of electric boats. Strater and Planson also worked with Coastal Enterprises, Inc., a Maine-based community development financial institution focused on climate resilience, to establish a “ marine green” loan program that can make the up-front costs of switching to electric propulsion more accessible to small businesses. “ The more electric engines that are being employed in Maine helps lift the whole tide for everyone,” said Nick Branchina, director of CEI ’s fisheries and aquaculture program. As part of its marine green lending, CEI offers loans starting at $ 25 , 000 for small businesses to make the switch to electric propulsion and comfortably afford the cost of batteries or a shoreside charging installation. Planson said that as electrification moves beyond initial grant-funded projects, the challenge is keeping systems affordable. He said he wants to see other small business owners able to “ take a reasonable swing” at electric propulsion. Buying a boat, of course, is only the first obstacle. Electric vessel owners must also learn how to use their new propulsion systems and find a place to charge them. How Do Electric Boats Perform in Cold Weather? This summer, Leathers said he’s had no trouble making the nearly 2-mile (3-kilometer) round trip from the slip where he docks Heron in South Freeport, Maine, to his farm on Casco Bay. With a full charge, he can make trips slightly farther to meet distributors closer to Portland. But as temperatures drop this winter, Leathers said he’s not sure how far the outboards’ two batteries will take him. Cold weather can reduce battery capacity and impact performance, shrinking an electric motor’s range. It’s a part of Leathers’s demonstration to find out what the impacts are in practice. Like Leathers, Strater and Planson also work year-round. They said they’re both impressed with how their boat performed last winter after launching in the fall of 2024 . For Planson, who markets battery-powered equipment to aquaculture farmers as part of his startup, Shred Electric , a boat’s ability to run through the year’s coldest months is a key selling point. “ The proof is in the pudding,” said Planson. “ When you’re working with…waterfront applications, it really needs to work every day and all year.” Strater and Planson said their boat’s range was an important consideration when they partnered with the startup Flux Marine to build the electric outboard motor. With limited shoreside charging infrastructure in place, the boat has to make it out and back on a single charge, sometimes to aquaculture operations 7 miles (11 kilometers) away. In the 10 months since the boat’s launch, Strater has learned that range correlates to speed. He can modulate the boat’s pace depending on how far he wants to go. “ We can go really fast for a short distance. We can go really slow for a long distance, and it works for what we do with it,” he said. Soon, Maine’s early adopters will have shared access to a higher-capacity Level 2 charger that will be installed at the Sea Meadow Marine Foundation and can charge batteries in little over 2 hours, or three times as fast as the current system. The startup Aqua SuperPower was awarded a portion of the DOE funding last year to install additional marine chargers there and at a wharf in Portland owned by the Gulf of Maine Research Institute. Island Institute also helped with grant funding for the charger at the Sea Meadow boatyard. Maine will need much more high-capacity charging infrastructure for the marine industry to transition to electric propulsion, said Morris, of the Island Institute. As the state’s aquaculture and fisheries industries look to grow beyond small-scale operations, other businesses will need to charge more frequently to make longer, farther trips up and down the coast. Expanding charging stations north of Casco Bay represents what Morris calls a “ chicken and egg” problem: a dynamic where chargers are either installed before demand gets high and sit unused, or electric boats hit the water and there’s not enough charging infrastructure, stalling future adoption. This challenge is compounded by both New England’s aging grid infrastructure and the remote nature of some of the region’s waterfront access points. Getting the right amount of power to a charging station on the shore can be costly, even in Yarmouth, which sits on Casco Bay. Often it’s the last mile that can be the most expensive. At Sea Meadow Marine Foundation, three-phase power, which can accommodate higher loads, is limited by the dirt road that separates the boat launch from the more heavily trafficked U.S. Route 1 . “ There are a lot of complicated questions,” Morris said. “ I don’t think it’s unique to Maine, it’s any rural area, but complicated questions and conversations with the utilities and the rural municipalities are going to have to be solved for.” Back on the water, Leathers docked his electric boat, Heron, alongside the sea farm’s barge, where thousands of oysters pass through for processing on harvest days. He switched the motor off and hopped onto the floating platform. For a moment, the bay was calm to the point of near silence. Then Leathers picked up an oyster cage with a rattle, turning it over in his hands as water splashed out. The sounds of the workday began. “ As a whole industry, I think it’s going to take proving that someone like us can do it,” Leathers said. “ And then the next person kind of snowballing after that.”",
    "published": "Mon, 29 Sep 2025 16:00:04 +0000",
    "author": "Julia Tilton",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "The Real Story on AI’s Water Use–and How to Tackle It",
    "link": "https://spectrum.ieee.org/ai-water-usage",
    "summary": "AI is hot, capturing headlines, investments, and users. It also runs hot, literally: The data centers operating artificial intelligence models use large amounts of electricity and generate enormous heat. To keep servers from overheating, many facilities rely on cooling systems that use water. AI data centers’ water use comes in two forms. Beyond the water that cools the servers, data centers indirectly contribute to water use through the electricity generation needed to power their operations. That indirect use often makes up 80 percent or more of the overall water use. Reducing AI’s water footprint means tackling two very different issues—what happens inside the data-center walls, and what happens beyond them on the power grid. Direct Water Use: Local and Sometimes Stressful Just as human bodies cool themselves by sweating, data centers are often cooled by water evaporation—a process that dissipates heat and results in water being lost to the atmosphere, thus being counted as “consumed.” In many cases, the water is drawn from the same municipal systems that supply homes and businesses. While most major tech companies now disclose their direct water use, not all data centers follow suit , making the overall picture unclear. In recent reports, companies have estimated that between 45 percent and 60 percent of withdrawn water is consumed. According to a recent report by Lawrence Berkeley National Laboratory, the 2023 direct water consumption by data centers in the United States—home to about 40 percent of the world’s data centers —is estimated at roughly 17.5 billion gallons . Assuming a 50 percent consumption ratio, that means 35 billion gallons of water withdrawal, or about 0.3 percent of the total public water supply for the contiguous United States. The same report projects that the U.S. data center direct water consumption could double or even quadruple the 2023 level by 2028. On the national level, data centers’ water use is relatively modest. But in some regions where data centers are concentrated—and especially in regions already facing shortages—the strain on local water systems can be significant. Bloomberg News reports that about two-thirds of U.S. data centers built since 2022 are in high water-stress areas . In Newton County, Georgia, some proposed data centers have reportedly requested more water per day than the entire county uses daily. Officials there now face tough choices: reject new projects, require alternative water-efficient cooling systems, invest in costly infrastructure upgrades, or risk imposing water rationing on residents. The biggest stress may not be total use, but timing. On hot days when residents and businesses need water most, data-center water demand spikes too. In Arizona, a data center’s monthly water usage during the summer can be nearly twice its average level . Indirect Water Use: Thirsty Electricity The other part of the equation is the electricity that powers data centers. In many places, electricity—whether for training AI models in data centers or turning on a lightbulb in a home—is generated by fossil-fuel-based power plants that require cooling water of their own. The U.S. electric power sector withdraws about 11.6 gallons of water and consumes 1.2 gallons for every kilowatt-hour of electricity produced, placing it among the nation’s largest water users . The water used to produce the electricity that powers data centers is considered indirect water use. The water used by power plants is typically not potable and not drawn from municipal water systems. Still, it can place stress on rivers, aquifers, and ecosystems—especially in water-scarce regions. For most U.S. data centers, this indirect use is significantly higher than direct onsite water use. One paper estimated that in 2023, using GPT-3 to generate a single text output of 150 to 300 words consumed a total of 16.9 milliliters of water in an average U.S. data center—2.2 ml for onsite cooling and 14.7 ml for electricity generation. It’s likely that efficiency gains in later models have reduced these numbers, but indirect water use still predominates. How to Minimize Data Centers’ Water Impact Unlike electricity, data-center cooling systems are a design choice. Evaporative cooling is low-cost and efficient, but it can burden local supplies during summer heat waves, when water is most needed and least available. To manage that peak demand, data centers can build onsite water storage or install thermal-energy storage. Upgrading water infrastructure—such as expanding distribution or fixing leaks—can also help local systems better handle demand spikes. Alternatives to evaporative cooling include air-based and liquid-immersion cooling , using recycled water to cut potable water use, and waste-heat reuse to reduce cooling demand. Some advanced designs recycle cooling water in a closed loop, so no water is consumed; these “zero water” designs eliminate the need to tap into local drinking water supplies. However, many of these designs raise electricity demand, which in turn can increase indirect water use. Water-cooled data centers consume about 10 percent less energy than air-cooled data centers. In immersion cooling systems, servers are submerged in a fluid that carries heat away without evaporating water. Jason Alden/Bloomberg/Getty Images In water-stressed regions, the priority should be low- to zero-water cooling systems to reduce direct use, while investing to add renewables to the local grids to curb indirect water use and minimize carbon emissions from higher electricity demand. In wetter regions with carbon-intensive grids, priority should be given to reducing power use to lower the overall water consumption, even if that means continued use of evaporative cooling with its higher onsite water consumption. The reality of the intertwined water and electricity systems forces data-center operators to navigate tough trade-offs between global climate goals and local water needs. These choices often aren’t simple, but until renewables dominate electricity grids, they may be unavoidable. The views expressed in this article are those of the authors and do not necessarily reflect the views of their employers or affiliated institutions.",
    "published": "Wed, 10 Sep 2025 13:00:04 +0000",
    "author": "Amy Luers",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "If We Want Bigger Wind Turbines, We’re Gonna Need Bigger Airplanes",
    "link": "https://spectrum.ieee.org/wind-turbine-blade-transport-plane",
    "summary": "The world’s largest airplane, when it’s built, will stretch more than a football field from tip to tail. Sixty percent longer than the biggest existing aircraft, with 12 times as much cargo space as a 747, the behemoth will look like an oil tanker that’s sprouted wings—aeronautical engineering at a preposterous scale. Called WindRunner, and expected by 2030, it’ll haul just one thing: massive wind-turbine blades. In most parts of the world, onshore wind-turbine blades can be built to a length of 70 meters, max. This size constraint comes not from the limits of blade engineering or physics; it’s transportation. Any larger and the blades couldn’t be moved over land, since they wouldn’t fit through tunnels or overpasses, or be able to accommodate some of the sharper curves of roads and rails. This article is part of The Scale Issue . So the WindRunner’s developer, Radia of Boulder, Colo., has staked its business model on the idea that the only way to get extralarge blades to wind farms is to fly them there. “The companies in the industry…know how to make turbines that are the size of the Eiffel Tower with blades that are longer than a football field,” says Mark Lundstrom , Radia’s founder and CEO. “But they’re just frustrated that they can’t deploy those machines [on land].” Radia’s plane will be able to hold two 95-meter blades or one 105-meter blade, and land on makeshift dirt runways adjacent to wind farms. This may sound audacious—an act of hubris undertaken for its own sake. But Radia’s supporters argue that WindRunner is simply the right tool for the job—the only way to make onshore wind turbines bigger. Bigger turbines, after all, can generate more energy at a lower cost per megawatt. But the question is: Will supersizing airplanes be worth the trouble? Wind Turbine Blade Transportation Challenges Lundstrom, an aerospace engineer, founded Radia nine years ago after coming across a plea for help from wind-turbine manufacturers. In their plea, posted as a press release, the manufacturers said they could build bigger onshore blades if there were simply a way to move them, Lundstrom recalls. In the United States, for example, the height of interstate highway overpasses—typically 4.9 meters (16 feet)—won’t allow for bigger turbine blades to pass. The overpass limitation is true for Europe too. There’s more flexibility in the developing world, where there are fewer tunnels and overpasses generally, Lundstrom says. But many of the roads aren’t paved or hardened, which makes it much tougher to move 50-tonne objects around. Some regions in China don’t have the same road constraints, allowing extralarge onshore wind turbines to be built there. Last year, Chinese multinational Sany Renewable Energy announced that it had installed a 15-megawatt model in Tongyu , Jilin province, in northeast China, with blades that are 131 meters long. The blades were manufactured in an industrial park in Inner Mongolia, an 1,800-kilometer trek from where they were ultimately installed. The WindRunner Offshore wind farm developers suffer from the logistical and practical challenges of operating in open ocean, but finding vessels big enough to transport the blades isn’t one of those. The biggest offshore blades measure nearly 150 meters, and they’re usually transported via cargo ship. Manufacturers typically locate their facilities on the coast . Onshore, the movement of blades has met the hard limits of infrastructure. Shipping them in multiple pieces and reassembling them on-site won’t work because the joints would create weak spots. Junctions would also add too much weight compared with that of blades made from single pieces of polymer, says Doug Arent , executive director at the National Renewable Energy Laboratory Foundation and emeritus NREL researcher. “It comes down to the stress engineering of the components,” Arent says. Blades could one day be 3D-printed on-site, which could negate the need for an airplane, but that research is still in early stages, he says. (Lundstrom says 3D-printed blades will never happen, since it would require a large, sophisticated manufacturing facility to be built at every wind farm.) If moving blades in pieces is folly, then the way forward is to fly. But even the largest existing cargo planes—the C-5 and C-17 flown by the U.S. Air Force and the Russo-Ukrainian Antonov AN-124 Ruslan—can’t accommodate large turbine blades. “There really is no big cargo aircraft in production, or planned, except for ours,” Lundstrom says. How to Make the World’s Largest Aircraft Fly What you can experience of Radia’s WindRunner today fits inside a conference room in the company’s Boulder headquarters. Here, a kind of gazebo made of two-by-fours houses a flight simulator, where I’m trying to virtually fly, and land, the behemoth. There’s a couple of pilot chairs, a joystick, a throttle, a video screen with a head-up display, and a few buttons to operate the simulated landing gear and wing flaps. The grid of flight instruments that will occupy the cockpit space above the pilot’s head are not finished yet. Instead, laminated pictures of the eventual controls are Velcroed in place. It takes surprisingly few levers and controls to fly the WindRunner. “Physics is physics,” says my copilot Etan Karni , principal engineer and head of Radia’s advanced systems groups. As Karni controls the WindRunner’s airspeed, I pull up on the joystick and guide it off the runway of a virtual Denver International Airport. A few minutes later I make a planned U-turn around a nearby lake. The maneuver is wobbly; I remind myself to move the joystick gently even though this is such a big bird. The WindRunner With Karni’s aid in controlling the landing gear and flaps, we set down back in Denver. I not only keep the WindRunner in one enormous piece but also bring it to a stop at the very front of the runway, just before the visible streaks of burned rubber from other airliners. In the real world, this remarkable feat of deceleration will enable the WindRunner to stop within 10 lengths of the aircraft—about 1,080 meters. And the aircraft won’t need the perfected runways of contemporary airports. It’s designed, by necessity, to land on and take off from rugged dirt tracks—like access roads on the perimeter of a wind farm, but wider. These capabilities are enabled by the plane’s relatively light weight, its wing and body shape, and its big tires. Optimized for cargo volume rather than mass—because turbine blades are huge but not dense—WindRunner is, effectively, one giant cargo hold with the bare minimum of amenities required to make it fly. “Landing on dirt basically comes down to how many pounds per wheel you have,” Lundstrom told me. WindRunner’s four jet engines will aid with short takeoffs. “When the aircraft is empty,” Lundstrom says, “the engines are so powerful that the vehicle has a thrust-to-weight ratio similar to early fighter jets.” (Radia chose an engine already in use by modern airlines, but hasn’t disclosed which one.) To allow the plane to quickly turn skyward without scraping its underside, its back end will sweep away from the ground at a sharp angle. A single tail tall enough to stabilize the WindRunner would exceed airports’ height limit of 24 meters, so Radia designed it with two risers in the shape of the letter H . For landings, the aircraft’s broad and stubby wings use their nearly 1,000-square-meter surface to catch air and decelerate quickly. Twenty big tires borrowed from the classic design of the U.S. Air Force’s C-130 Hercules will help WindRunner slow down after it touches the ground. The plane’s mouth flips up to reveal its cavernous interior, a feature borrowed from the Antonov An-124. The cockpit, itself about as big as an entire Gulfstream private jet, looks like a pimple bulging from the WindRunner’s staggering frame. It sticks out from the fuselage to avoid interfering with cargo space and is the only part of the plane designed for human habitation. During flight, the hold is only pressurized to about the level of the peak of Mt. Everest, to save energy. Why Wind Turbines Got Bigger During my visit to Radia, a virtual-reality headset lets me behold the colossus from underneath its wing and inside its cargo bay. It feels like standing next to a warehouse that can fly. Seeing the virtual superplane towering above, and grasping the plane’s monumental scale makes me wonder if this adventure in engineering is necessary, that surely there’s another way. The largest helicopters built in the Western Hemisphere can carry up to 15 tonnes, but megablades can weigh four to five times that, Lundstrom notes. Blimps and airships can carry the weight, but they bring a laundry list of complications. They’re too slow, need an expensive hangar to shield them from bad weather, require helium—which is currently scarce—and struggle to land when it’s windy. “And by the way, wind farms tend to be windy,” he says. And, since the world’s biggest cargo planes can’t be stretched to meet the length of a 100-meter blade, nor can they land on short, rugged runways, a new design is needed. Still, the fundamental question remains: Is increasing the size of onshore wind turbines by 50 percent worth the trouble? Michael Howland , a wind-optimization expert at MIT, says there’s a huge value proposition in it. A turbine’s power-generation capacity increases by the cube of the wind speed blowing through it and the square of the diameter of the circle created by the spinning blades, he says. In other words, bigger turbines, while more expensive per individual unit, more than make up for it in generating capacity. That’s why the size of turbines has grown steadily larger over the years. “You’re able to have half as many,” Lundstrom adds. “So even though the cost of each turbine has gone up, the cost per gigawatt goes way down.” He estimates that GigaWind turbines would decrease the cost of energy by 20 to 35 percent while increasing output by 10 to 20 percent, potentially doubling wind’s profitability even with the cost of all those flights included. Having fewer total turbines means a wind farm could space them farther apart, avoiding airflow interference. The turbines would be nearly twice as tall , so they’ll reach a higher, gustier part of the atmosphere. And big turbines don’t need to spin as quickly, so they would make economic sense in places with average wind speeds around 5 meters per second compared with the roughly 7 m/s needed to sustain smaller units. “The result…is more than a doubling of the acres in the world where wind is viable,” Lundstrom says. Upon the WindRunner’s landing at a wind farm, rail equipment will roll turbine blades off the plane. Radia To kick-start this market, and to support the first WindRunners, Radia is developing a business arm that partners with wind-turbine manufacturers to develop new wind farms both domestically and internationally. WindRunners would deliver blades to those farms and those developed by other companies. The scope of Radia’s plan, and the ambition behind it, has impressed many observers, including Howland. “I was both surprised but also very impressed by the innovative spirit of the idea,” he says. “It’s great to be ambitious in terms of solving the grand challenges.” But onshore “gigawind” is full of unknowns, he notes. Less is understood about the flow physics and engineering of record-breaking turbine sizes. Plus, huge blades could create wakes so large that the turbines behind them would be noticeably affected by variations in air temperature and even the Coriolis effect caused by Earth’s rotation, and might require innovation in fundamental science, he says. Then there’s the question of the big plane’s carbon footprint. To move enough blades for a whole wind-farm operation, a WindRunner might fly back and forth from factory to farm every day for months, carrying one or two blades at a time. This may create more carbon emissions compared with trucking them. But Radia argues that the increased amount of clean energy created by advanced wind farms would be far more than enough to offset the CO 2 from the jet engines. Besides, the biggest component of a wind farm’s carbon footprint is the concrete and steel. With longer blades allowing for fewer turbines to create the same amount of energy, carbon contributions should decrease, Lundstrom argues. As Radia continues its quest, a dark cloud hangs over the endeavor. U.S. President Donald Trump and his administration have made multiple attempts to grind the American wind-energy industry to a halt by pausing approvals, permits, and government loans. But Lundstrom pushes back against the notion that the prevailing winds out of Washington will clip Radia’s wings. There’s simply too much money to be made, he says. “My belief is that [it’ll] sort itself out….We’ll be delivering [planes] at the end of this administration,” Lundstrom says. Increasing the scale at which societies can produce wind power is crucial for a future without fossil fuels. And that scale, he says, can’t be reached without a new airplane to make it possible. This article was updated on 17 September 2025. This article appears in the October 2025 print issue as “An Airplane Longer Than a Football Field.”",
    "published": "Wed, 10 Sep 2025 12:00:04 +0000",
    "author": "Andrew Moseman",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Maximizing Solar ROI with Smarter Balance-of-System Solutions",
    "link": "https://content.knowledgehub.wiley.com/how-to-optimize-solar-bos-for-value-and-efficiency/",
    "summary": "This white paper addresses the challenge of rising balance-of-system (BOS) costs in solar energy projects, which now make up a larger share of total system expenses due to falling solar module prices. It provides valuable insights for engineers, developers, and EPCs on how to optimize BOS components for efficiency, reliability, and lower total cost of ownership. Readers will learn how to reduce labor, avoid costly installation errors, and improve long-term performance through better product selection, installation tools, mock-up testing (golden rows), and Panduit’s comprehensive BOS solutions that bundle, connect, protect, and identify system elements. Download this free whitepaper now!",
    "published": "Mon, 08 Sep 2025 17:55:23 +0000",
    "author": "Heilind Electronics",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "The Unlikely Revival of Nuclear Batteries",
    "link": "https://spectrum.ieee.org/nuclear-battery-revival",
    "summary": "In 1970, surgeons in Paris implanted the first nuclear-powered pacemaker, and over the next five years, at least 1,400 additional people received the devices, mostly in France and the United States. Encased in titanium, the batteries for these devices contained a radioactive isotope—typically about a tenth of a gram of plutonium-238—and could operate for decades without maintenance. The invention provided relief to a population of people who previously needed surgery every few years to change out their pacemaker’s chemical battery. As time went on, though, the whereabouts of these radioactive tickers became increasingly difficult to track. In the United States, the devices were supposed to be returned to the U.S. Department of Energy for plutonium recovery. But often, that didn’t happen. Doctors changed jobs, manufacturers went out of business, patients died, and families forgot about their loved one’s pacemaker. Too often, the radioactive material landed in crematoriums and coffins. Uncomfortable with the situation, regulators worldwide nixed the devices. The last known nuclear-powered pacemaker was implanted in 1988. After that, aside from a few specialty uses, such as deep-space probes and Siberian lighthouses, development and deployment of nuclear batteries effectively came to a halt. Medtronic’s 1970 Laurens-Alcatel pulse generator powered pacemakers with plutonium-238. Smith Collection/Getty Images Technology never truly dies, and nuclear batteries are no exception. Research grew active again after 2000 , although it lacked commercial translation. But over the last year, a host of companies and research groups around the world have announced advances that they say will invigorate the technology and extend its use to robots, drones, sensors, and solar farms, as well as spacecraft and biomedical implants. The new groups are employing modern, more-exotic technology that goes beyond the designs of the past, allowing them to pursue the finest nuclear batteries ever made. As with the first generation, the allure of nuclear batteries is still their extraordinarily long life-spans: several decades and, with proper fuel choice, possibly centuries. They could also deliver more energy in packages that weigh less than those of chemical batteries. The question is, who’s going to buy them? I’ve been involved in this sector for nearly 40 years as a nuclear engineer, professor, and consultant. Here’s what I’ve observed: The technology works, it has many advantages over chemical batteries, and it can be utilized safely. But what very few companies have been able to do is find a new market for these batteries and make a product that has an impact. Part of the problem is that there is no good solution to the need to track these sources and make sure they are disposed of properly at the end of the battery’s life. There are more companies working out the challenges now than I’ve ever seen in my career, and that’s good for the field—it helps ground the academic research. And it gives me hope that this could be the moment when nuclear batteries finally flourish. How Do Nuclear Batteries Work? The term “nuclear batteries” may evoke images of tiny nuclear reactors, but that’s not how they work. Nuclear batteries don’t split atoms with neutron bombardment. Instead, they capture energy in the form of radiation that’s spontaneously released when atomic nuclei decay. Most research groups developing nuclear batteries are focused on harnessing energy from radioactive isotopes of nickel and hydrogen. In many nuclear battery designs, adjacent semiconductors absorb the radiation released by the radioisotopes’ nuclei and convert it to an electric current, much like a solar cell does. In other designs, thermoelectric devices convert the heat produced by the emitted radiation to electricity. So “radioisotope power source” is a better descriptor than “nuclear battery,” but for ease of language, I’ll use these terms interchangeably. Infinity Power uses a novel electrochemical process to convert the radioactive decay of nickel-63 into electricity. The company says it can scale the technology from microwatts to megawatts. Infinity Power On the heels of some laboratory successes, researchers are racing to commercialize these devices. The United Kingdom Atomic Energy Authority (UKAEA), Miami-based City Labs , Beijing Betavolt New Energy Technology Co., and China’s Northwest Normal University have all announced advances and funding in semiconductor-based nuclear batteries over the last two years, some with plans to commercialize. Last year, Infinity Power , in San Diego, announced a novel electrochemical approach to converting radioisotope energy. What markets these batteries will find—if they can be commercialized—will depend largely on cost, safety, and licensing issues. One of the most compelling applications is in uncrewed spacecraft for long-distance missions, which require decades of reliable power. Solar power works for missions close to the sun, but by the time a spacecraft gets to Jupiter, the available solar irradiance drops below 4 percent of that on Earth. That leaves nuclear fission and radioisotope power as the only viable options for deep-space missions. Fission is ideal for larger power needs in space, like NASA’s proposed 100-kilowatt lunar nuclear reactor . But for lower, onboard power needs, nuclear batteries offer simpler designs and lower mass. The current radioisotope workhorse in space is the radioisotope thermoelectric generator, or RTG, which produces a few hundred watts. Radioisotopes: Not Just for Nuclear-Powered Pacemakers NASA’s two Voyager missions, launched in 1977, each carry three RTGs that weigh about 38 kilograms, including 4.5 kg of plutonium-238. They’re cylindrical and about the size of an office wastebasket. They initially produced 157 watts of electric power, but that drops over time as the plutonium-238 decays. A 157-W Voyager-based RTG that launched in 1977 will produce about 88 W today. Another good use for nuclear batteries is to supply power in remote locations on Earth. Beginning in the 1970s, for example, the Soviet Union deployed over 1,000 RTGs in northwestern Russia to power its uncrewed lighthouses, radio beacons, and weather stations. Most of these batteries ran on strontium-90, and each weighed about 2,000 kg. The United States has deployed hundreds of similar systems for remote power both on land and on the ocean floor, particularly for remote monitoring sites in the Arctic . While nuclear batteries have proved successful for space exploration, remote power, and pacemakers, no new uses for these long-lived batteries have emerged. Many devices would benefit from long-lived batteries—imagine a wireless tire pressure sensor that lasts the life of a car, for example. But the risks and costs of opting for a radioactive battery would have to be balanced against the benefits. Another factor working against the widespread use of nuclear batteries is the need to track the fuel. In just about any country, the sellers and buyers of any such batteries intended for the general public would need to be licensed (see box, “Boy Amasses Large Quantity of Radioactive Material in His Home: A Cautionary Tale”). The buyer also typically takes on the burden of tracking and disposing of the material. Keeping tabs on radioactive material is a necessity, but this adds complexity to applications involving the general public. Boy Amasses Large Quantity of Radioactive Material in His Home: A Cautionary Tale In just about any country, buyers of radioisotope fuel sources must be licensed—with some exceptions. In the United States, for example, you don’t need a license for some radioisotopes if the quantity is below a certain level set by the U.S. Nuclear Regulatory Commission. Many smoke detectors contain about 1 microcurie, or 37,000 becquerels, of americium-241, which is below the exception limit of 5 µCi (185,000 Bq). (The radioisotope ionizes the air within the detector, and the alarm is triggered when the presence of smoke alters the ionization rate.) The exemption quantities are too small for even the smallest nuclear battery—unless someone starts up a collection. That’s just what a young man in Michigan in the 1990s did. Between the ages of 14 and 18, he attempted to build a neutron generator by collecting americium from smoke detectors, thorium from camping-lantern mantles, radium from old clocks, and tritium from gunsights. He amassed so much radioactive material that the U.S. Environmental Protection Agency declared his home a Superfund hazardous waste clean-up site. But the benefits of radioisotopes are profound, and we shouldn’t be afraid to use them with proper care. They’re used worldwide on a daily basis primarily for medical imaging and cancer therapy. They’re also used as tracers to monitor fluid flow and detect leaks, for nondestructive inspection of welds, and for explosive detection.—J.B. One new use where the benefits may outweigh the risks and costs is providing longer-lived power to soldiers—something the U.S. military has explored. Soldiers’ missions often take them to remote or unstable locations where electricity may be unavailable, preventing them from charging their equipment. This forces soldiers to carry batteries, the weight and life of which limit their missions. Small nuclear batteries would provide a lightweight alternative—potentially 1/100 the weight—due to their higher energy density relative to that of chemical batteries. But they would need to be encased to shield soldiers from the radiation, and designed to withstand harsh conditions, which would add weight. Another potential new use for nuclear batteries is to power autonomous sensors or robots that communicate, move, or fly. One compelling use would be insect-size flying microdrones for civilian and military purposes. But collecting them at the end of their flights might be difficult and would also leave tiny bits of radioactive material littering the landscape. Engineering Challenges: Betavoltaics Versus Alphavoltaics Let’s turn to the engineering challenges of commercializing a miniature nuclear battery. In general, taking a promising battery technology from the lab to mass production is a complex process that’s more likely to end in failure than success. With nuclear batteries, it involves negotiating a lot of trade-offs between cost, power, safety, and life-span. First, you have to pick the fuel—that is, an isotope of an element that will release radiation as it decays. Such isotopes emit three types of radiation: gamma rays, beta particles, and alpha particles. Gamma rays are short-wavelength electromagnetic waves that can travel deep into most solids, including living tissue. They’re difficult to contain and capture, so gamma-emitting isotopes are typically avoided. Table 1: Radioisotopes Used in Nuclear Batteries Isotope Type Maximum decay energy (kiloelectron volt) Half-life (year) Specific power (watts per gram) Tritium beta 19 12.3 0.33 Carbon-14 beta 156 5,730 0.0013 Nickel-63 beta 67 100 0.0058 Promethium-147 beta 225 2.6 0.41 Polonium-210 alpha 5,305 0.38 141 Plutonium-238 alpha 5,593 87.7 0.56 Credit/source: Jake Blanchard Radioisotopes emit particles with a spectrum of energies. The decay energy is a measure of the kinetic energy of emitted particles as the radioisotope decays. The specific power provided here is a measure of how much power an ideal, pure radioisotope source can generate per unit of mass at the beginning of its life. Pure beta or alpha emitters are a better choice for nuclear batteries. Beta particles are electrons that have an intermediate penetration range in solids. Their decay energies go from a few kiloelectron volts (for tritium, or hydrogen-3) to a few megaelectron volts (for yttrium-90). Alpha particles, by contrast, are emitted at a higher energy than beta particles—typically around 5 MeV—and can’t penetrate a piece of paper. But they can damage semiconductors by creating defects as they collide with the nuclei in the device. This makes alpha emitters best suited for non-semiconductor battery technologies that convert the heat generated by the source fuel into electricity. Radioisotopes of nickel, carbon, hydrogen, sulfur, promethium, polonium, and plutonium all emit beta or alpha particles and are good options for nuclear batteries (see “Table 1: Radioisotopes Used in Nuclear Batteries”). Which one to choose depends on several factors, including the isotope’s half-life and its decay energy. For the longest battery life, you’ll want a radioisotope with a long half-life, because the battery’s output power will drop by a factor of two over each half-life. That means a tritium-fueled device will lose half its power every 12 years, while a plutonium-238 battery will lose half its power every 88 years. What very few companies have been able to do is find a new market for these batteries and make a product that has an impact. If your goal is instead to maximize the battery’s power density—such as for an insect-size microdrone—then you’ll need one with a short half-life . For example, polonium-210 has a half-life of a few months, but a power density of 141 watts per gram, which could give it enough power to carry its payload. The short half-life would mean it would work only for a few months and would completely decay within a couple of years. But for a microdrone that will probably be abandoned somewhere, perhaps that’s a good thing. (Note that these power densities account for thermal power, but there are losses in converting to electricity, so the output power density of any devices created using this fuel will be lower.) The safest nuclear battery fuels are tritium and nickel-63, because they produce low-energy beta particles that are easier to shield and less damaging to semiconductors than alpha particles. Pure tritium can be challenging to work with because it’s a gas at room temperature. It can be converted into a metal hydride, but this process, which involves mixing it with stable isotopes, decreases its energy density. Another design consideration is that the lower penetration depth of these safer, low-energy beta emitters requires that the sources be made very thin, or else the particles will never reach the battery’s semiconductor. What about supply and cost? All radioisotopes are expensive to procure and are typically only available in small quantities. Just about any of them can be made during nuclear fission by placing a dedicated target material in the reactor core. They can also be made using particle accelerators. Some types of radioisotopes can be obtained from spent nuclear fuel. But none of these options is simple or inexpensive, because every step requires the handling of radioactive materials. One gram of tritium costs about US $30,000 and will produce a thermal power of about 0.3 W, which would in turn typically produce an electric power of only a few milliwatts. The supply of plutonium-238 is so limited that NASA must set its launch schedule according to the availability of the fuel. As a result, NASA is pursuing americium-241 as an alternative. It’s unclear how these costs would change if the market for these materials grows substantially. How to Convert Radioisotope Power Sources After choosing a fuel, you have to select a conversion technology. Early radioisotope power sources developed in the 1950s simply collected the charged decay particles, producing an electric potential difference between the collector and the source—that is, a voltage—that could then be tapped to produce electricity. The current in these designs was inherently low, and so the battery had to be run at a high voltage (in the kilovolts) to achieve a reasonable conversion efficiency, which proved too challenging. To get around this problem, you can use a semiconductor to turn each charged particle emitted by the source into thousands of charge carriers, allowing the device to run at a few volts instead of a few kilovolts. The physics of such a device is essentially that of a solar cell, except that the source of the radiation is from a radioisotope instead of the sun. When the radioisotope is a beta-particle emitter, we call the device “betavoltaic.” Three Other Ways to Convert Radioactivity Into Electricity As radioactive isotopes decay, their nuclei spontaneously release energy in the form of radiation . The energy can be captured, converted into electricity, and stored, creating a nuclear battery. In common designs, adjacent semiconductors absorb the radiation and convert it to an electric current, or thermoelectric devices convert the heat that radioisotopes produce to electricity. But more-exotic techniques such as radioluminescent, thermionic, and thermophotovoltaic conversion are also being explored. Radioluminescent conversion In this approach, a scintillator, such as a cerium-doped lutetium aluminum crystal, is exposed to ionizing radiation from the isotope, causing it to emit light. The light is captured and converted to electricity with a photovoltaic cell, which can be tuned to the frequency of the emitted light to improve conversion efficiency. But the light production itself is inefficient. Thermionic Conversion This concept uses the radioisotope to produce a hot surface (typically above 1,500 °C), which then releases electrons via thermionic emission. The source is heated as the emitted particles deposit their kinetic energy in the solid through interactions with the source atoms. The electrons emitted by the surface can be collected to produce a potential and a current source. Conversion efficiency can reach 20 percent, but achieving the necessary temperatures requires large sources, so this technology is only appropriate for high-power applications. Thermophotovoltaic Conversion This strategy uses a radioisotope to produce a hot surface, and electromagnetic radiation from the hot surface produces electricity within a photovoltaic cell. To obtain good efficiencies, these devices must run very hot—around 2,000°C for a conversion efficiency of 29 percent. Under development since the 1950s, betavoltaic batteries feature a radioactive emitter and a silicon-diode absorber. As the emitter naturally decays, electrons (in the form of beta particles) strike the absorber. This creates a cascade of electron-hole pairs, which occur when electrons are removed from their original position, leaving a “hole” that generates a small but stable supply of electric current. This process is similar to that of a solar cell, where light produces the electron-hole pairs. Betavoltaic batteries with silicon diodes have conversion efficiencies of a few percent, and up to 10 percent with silicon carbide, and can typically operate at around 1 volt. Some models indicate that this efficiency can be as high as 23.5 percent . Recent research on betavoltaics uses diamond semiconductors, which offer even higher conversion efficiencies due to their higher bandgap. Betavoltaics are solid-state, simple, and relatively inexpensive, so they offer an ideal way to produce a low-power option (less than about a milliwatt) for nuclear batteries. They can be used to create higher-power devices, but in those cases it’s often better to switch to an alpha emitter to achieve a higher power density. However, because the alpha particles will damage a semiconductor, their use generally requires a conversion option that relies on heat converted to electricity. For example, NASA uses thermoelectric conversion in its RTGs, which have been used to power not only Voyager 1 and 2 , but also two Mars rovers and over 40 other NASA missions . If you’ve seen the movie The Martian , you may recall how Matt Damon’s character, trapped alone on Mars, used an RTG: He needed a heat source to stay warm while traveling in a rover, so he dug up an old RTG from a previous mission and placed it inside his vehicle. To convert the heat to electricity, the RTGs employ a series of thermocouples, which consist of a junction of two dissimilar conductors. These components produce a potential in the presence of a temperature gradient (via what’s known as the Seebeck effect). The pacemakers of the 1970s also relied on thermoelectric conversion, albeit on a smaller scale. Other, more-exotic conversion techniques include radioluminescent conversion, thermionic conversion, and thermophotovoltaic conversion (see sidebar, “Three Other Ways to Convert Radioactivity Into Electricity”), all of which work well in the lab but require higher operating temperatures or have degradation issues. Most companies are focused on developing betavoltaic technology because it permits the use of the safer beta emitters. Who Is Developing Nuclear Batteries? Since the invention of small betavoltaic power sources in the 1970s, the vast majority of research on nuclear batteries has focused on power levels of less than 1 microwatt (see “Table 2: Who’s Developing Nuclear Batteries”). To date, many of these efforts have been shrouded in secrecy, and there’s been a dearth of patents in the field, which has made it difficult to judge their features and merits. Beijing Betavolt New Energy Technology Co. says it has a 100-µW battery that’s about the size of a cereal square (15 by 15 by 5 millimeters) and can last 50 years. The company is working with betavoltaics using nickel-63, tritium, promethium-147, and strontium-90, and a diamond semiconductor to convert the energy to electricity. Table 2: Who’s Developing Nuclear Batteries Company/research group (location) Radioisotope Conversion technology Goals and accomplishments Beijing Betavolt New Energy Technology Co. Nickel-63 Betavoltaic with diamond diode semiconductor 100-microwatt battery; planning a 1-watt version for commercial launch Arkenlight (Bristol, England) Carbon-14 and tritium Betavoltaic with diamond diode semiconductor Exploring use in satellites, medical implants, industrial sensors, and luxury watches Daegu Gyeongbuk Institute of Science and Technology (Daegu, South Korea) Carbon-14 Betavoltaic with titanium dioxide semiconductor sensitized with ruthenium dye Presented results at American Chemical Society spring meeting, March 2025 City Labs (Miami) Tritium Betavoltaic Focused on space, deep ocean, and medical applications; 20-year battery life Northwest Normal University (Lanzhou, Gansu Province, China) and Wuxi Beita Pharmatech Co. (Wuxi, Jiangsu Province, China) Carbon-14 Silicon-carbide semiconductor Demonstrated by powering an LED United Kingdom Atomic Energy Authority (Oxfordshire, England) Carbon-14 Diamond semiconductor Envisioning applications in medical devices like ocular implants and hearing aids and in radio-frequency-tracking tags Infinity Power (San Diego, Calif.) Nickel-63 Electrochemical Technology can scale from microwatts to megawatts The Ohio State University (Columbus) Cesium-137 and cobalt-60 from spent nuclear fuel Radioluminescent conversion of gamma radiation Targeting power needs near nuclear-waste storage pools, and for space and deep-sea exploration Soochow University (Suzhou, China ) Americium-243 Radioluminescent Micronuclear battery for very low-power applications Beijing Betavolt last year announced plans to commercially launch a 1-W version in 2025, but as of press time, it was still seeking a license and funding to do so. Potential applications include aerospace, medical implants, wearable devices, MEMS systems, advanced sensors, small drones, miniature robots, law-enforcement equipment, and fire-safety remote communication. Assuming Beijing Betavolt’s device has a conversion efficiency of about 5 percent, the battery would have to hold about 20 curies, or 740 billion becquerels (0.4 grams), of nickel-63. This is well above the typical amount of nickel-63 available on the market, which is normally in the millicurie range. To date, many efforts have been shrouded in secrecy, and there’s been a dearth of patents in the field, which has made it difficult to judge their features and merits. Infinity Power also uses nickel-63 in its coin-size battery, but may need less of it because of the novel electrochemical conversion process it has developed. The company says its conversion efficiency exceeds 60 percent—about six times as efficient as the best radioisotope power generators. In Infinity’s design, the isotope is dissolved or suspended in a proprietary liquid electrolyte. The decay of the radioisotope produces high-energy beta particles that ionize the electrolyte, creating a potential difference between the anode and cathode immersed in the solution and driving electron flow through an external circuit to produce electricity. Academic and government researchers are also pursuing nuclear batteries. The University of Bristol, in England, and the UKAEA last year announced they had developed a battery fueled by carbon-14, a radioactive form of carbon. With carbon-14’s half-life of 5,700 years, the battery could theoretically last for millennia. The U.K. has an ample supply of the fuel because it can be scavenged from the country’s graphite-moderated, gas-cooled fission reactors. Carbon-14 produces beta particles with a maximum energy of 156 kiloelectron volt, which should be low enough to prevent damage to the battery’s diamond semiconductor. Meanwhile, a collaboration of researchers in China published a report in the December 2024 IEEE Transactions on Nuclear Science on a radioluminescent nuclear battery . The team used an X-ray source, which emits electromagnetic radiation, to mimic a beta source, which emits electrons, to help them understand how the device might perform. The X-ray photons excited two inorganic scintillators, causing them to emit light, and a commercial silicon photodiode converted the light to electricity. The products envisioned by these startups offer great promise. The key to their lasting success will be identifying markets in which the benefits of nuclear batteries outweigh the challenges. The market for these devices in space applications is strong, but whether new markets will arise remains to be seen. Acknowledgment: Special thanks to Yu-Tzu Chiu, who contributed reporting for this article.",
    "published": "Mon, 25 Aug 2025 13:00:00 +0000",
    "author": "James Blanchard",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "China, Russia, and U.S. Race to Develop Lunar Nuclear Reactors",
    "link": "https://spectrum.ieee.org/lunar-nuclear-reactor-nasa-moon",
    "summary": "China, Russia, and the United States are racing to put nuclear power plants on the moon. China and Russia in May agreed to work together to complete a lunar nuclear reactor by 2036 . In response, NASA’s interim chief Sean Duffy announced in August that the United States would fast track its lunar nuclear power program to have one ready by 2030. But this sudden frenzy raises a few questions—such as why do we want nuclear reactors on the moon in the first place? And how would they work? To find out, IEEE Spectrum spoke with Katy Huff , a nuclear engineer and the director of the Advanced Reactor Fuel Cycles Laboratory at the University of Illinois at Urbana-Champaign. Huff previously served as the assistant secretary for nuclear energy at the U.S. Department of Energy (DOE). Why do the world’s biggest space organizations want nuclear reactors on the moon, and what would they power? Katy Huff : There’s a growing interest in having a more sustained presence of humans on the moon for scientific discovery . Resources like helium-3, which can serve as a fusion fuel, may be part of the appeal. NASA is planning to build this kind of lunar exploration base through its Artemis program, and China and Russia are working together to build one called the International Lunar Research Station . Any such lunar base would absolutely need nuclear power. Renewables alone are too intermittent to meet the energy needs of life on the moon. Plus, the cost of getting things into space scales by mass, so the unmatched energy density of uranium fission is our greatest opportunity. Why is it suddenly a race? What’s the urgency? Huff: The momentum began with the fission surface power project at NASA, which a few years ago solicited designs for 40-kilowatt lunar microreactors. Three designs were selected and awarded US $5 million each. Since then, China and Russia have announced on at least three occasions a joint effort to design their own lunar microreactor with a launch target in the mid-2030s. In response, NASA is accelerating its timeline for the U.S. reactor to 2030 and increasing the target power capacity to 100 kW. Sean Duffy has said publicly that if China and Russia are the first to stake a claim for a lunar power plant, they could declare a de facto keep-out zone , limiting the United States’ options to site its base. So the U.S. aims to get there before China and Russia to claim a region with access to water ice, which aids life support for astronauts. Designing Lunar Nuclear Reactors What are the considerations for designing a nuclear reactor for the moon? Huff : In very low gravity, fluids won’t behave exactly as they do on Earth. So the circulation patterns for the reactor’s fluid coolants will need to be recalculated. And the moon’s large temperature swings, which vary hundreds of degrees from lunar day to night, will require the reactor to use systems that are more isolated from those swings. On Earth we eject waste heat easily because there are thermally stable heat sinks like water bodies available. What kind of reactor do you expect NASA to choose? Katy Huff previously served as the assistant secretary for nuclear energy at the U.S. Department of Energy (DOE). Katy Huff Huff : It would make sense if NASA chose one of the three designs previously selected for the fission surface power program, rather than starting from scratch. But with the over-doubling of target capacity, from 40 kW to 100 kW, there will be a bit of a redesign involved, because you don’t just turn up the knob. The three awards went to Lockheed Martin / BWXT , Westinghouse / Aerojet Rocketdyne , and X-energy / Boeing . Some of them are developing microreactors that are based around tristructural isotropic [TRISO] fuel , which is a type of highly robust uranium fuel, so I would expect the lunar reactor to be designed using that. For the coolant, I don’t expect them to choose water, because water’s thermal properties limit the range of temperatures it can cool effectively, which constrains reactor efficiency. And I don’t expect it to be liquid salt either, because it can be corrosive, and this lunar reactor needs to operate for 10 years with no intervention. So I suspect they’ll choose a gas such as helium. And then for power conversion, NASA’s directive explicitly said that a closed Brayton cycle would be a requirement. What would transport and startup look like? Huff : The reactor would be fully constructed on Earth and ready to go, with the fuel in place. My expectation is that it would be transported with the control elements fully inserted into the reactor to prevent a chain reaction from starting during transit. Once on the moon, a startup sequence would be initiated remotely or by the astronauts there. The control rods would then withdraw from the reactor, and a small neutron source like californium-252 would kick off the reaction. A deadline of 2030 feels pretty rushed considering the United States doesn’t have a final design for the reactor, nor firm plans for a lunar base. Huff : Right. That timeline does appear ambitious. We’ll have a hard enough time getting a reactor of this scale deployed as a prototype terrestrially in the next four and a half years. Getting one launch-ready and onto the moon by then is a recipe for eventually having to explain why we didn’t meet that timeline. And that could be a problem, reputationally, for nuclear energy more so than space exploration because people love NASA. Little kids and grown-ups alike wear NASA T-shirts. No one’s wearing DOE T-shirts. Risks of Lunar Reactor Launch What are the risks if something goes wrong with the launch? Huff : Beautifully enough, fresh uranium fuel doesn’t present a radiological hazard the way spent uranium would. Only after it becomes the fission products is it significantly radioactive. So as long as the reactor doesn’t operate before launch, the hazard is quite low. Even if the fuel were dispersed over the Earth, it wouldn’t pose a significant danger to the people around it. I literally have a sample of uranium sitting by my desk. On top of that, there’s a robust launch safety protocol already established for any radiological object. NASA has a lot of experience with this from sending plutonium thermoelectric generators , which are more like a nuclear battery, for previous missions. Things have gone wrong with some of the fission reactors previously launched into space; what happened to those? Huff : The biggest fission reactors anyone has launched into space were the 5 kW electric TOPAZ-I reactors that were part of the Soviet program. One of them had a serious incident and broke apart. It’s now in high orbit in pieces, including some of its sodium coolant, which is just sort of floating around up there as liquid metal spheres. But that doesn’t impact the Earth because it’s a tiny amount of radiological source material at an incredible distance from Earth. The more unfortunate incident happened with the Soviet Kosmos 954 reactor, which, after operating in orbit, experienced uncontrolled reentry and disintegrated over a 600-kilometer swath of Canadian territory. What happens if an asteroid hits the moon or directly hits the lunar nuclear reactor? Huff : A direct strike could damage the reactor and cause localized dispersion of the fuel. This might be a motivation to use TRISO fuel. It’s so robust because the fuel and fission products are housed in thousands of spherical, chia seed–size particles that are coated in silicon carbide. It can withstand incredible impacts and heat—well beyond the temperature of lava. Testing has shown that even when subjected to 1,700°C heat for 300 hours , TRISO retains its fission products with no failures. So in the unlikely event that there’s a dead-on collision with a large asteroid at the reactor site, the debris of the reactor may be distributed in the dust of the moon, but all those little TRISO particles will hopefully remain intact.",
    "published": "Fri, 22 Aug 2025 13:00:03 +0000",
    "author": "Emily Waltz",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "What It Will Really Take to Electrify All of Africa",
    "link": "https://spectrum.ieee.org/electricity-access-sub-saharan-africa",
    "summary": "I dined recently with Joe, a Nigerian who manages a 400-hectare rice farm in the north of his country. Nigeria imports about 2.4 million metric tons of rice annually, according to the U.S. Department of Agriculture. Farmers like Joe are helping to move his country of 237 million people toward self-sufficiency in rice. But farmer Joe has a handicap. “For me, the power grid is a fiction,” he says. “I don’t get any electricity from the grid, and I never will.” Five years ago, Joe installed solar panels to power his farm’s irrigation system, which draws water from a nearby river. His milling and bagging machines, meanwhile, still run on diesel generators. When Nigeria ended its fuel subsidy in 2023, Joe’s fuel costs soared, reducing the money he can invest in more land and other improvements. What is holding back Africa’s electrification? Joe’s predicament is not unique. In sub-Saharan Africa, 600 million people—about 53 percent—still have no access to electricity . Even this grim statistic understates the problem, because “access” can mean just enough wattage to illuminate a few LED lightbulbs some of the time. It’s not what Western Europeans or North Americans would consider electricity. And traditional power grids in sub-Saharan Africa are hampered by poor reliability and frequent outages. Even when offered electricity, many customers can’t afford to pay, and so theft of service is endemic. Where grids do exist, “they are outdated, unstable, and lack customer connections,” the United Nations Conference on Trade and Development (UNCTAD) reported in 2023 . “I’m a bit tired of imprecise measures of access if that access doesn’t translate into the potential for substantial improvements and increases in consumption,” says Christopher D. Gore , a professor of politics and public administration at Toronto Metropolitan University , who studies electricity usage in the region. “Our latest research shows that [sub-Saharan] households are happy to have any electric light but remain dissatisfied with the minimal supply, the price, and the quality of both grid and solar power.” The electricity deficit may well be worsening. In a 2024 report on universal energy access in Africa , researchers from the Center for Strategic & International Studies , in Washington, D.C., concluded that “demand is significantly outstripping supply, and the energy crisis is deepening.” To address this dire shortage , the World Bank and the African Development Bank announced an initiative last year called Mission 300 , to bring electricity to 300 million people in sub-Saharan Africa—about half the number who lack access now—by 2030. Such a rapid expansion means bringing electricity to an additional 4.2 million people every month on average. While plausible, the expansion faces headwinds, most notably from the sub-Saharan’s net population gain of about 2.5 million people per month. If that population growth continues for all six years of the initiative, there will be an additional 180 million people requiring electricity access. “The challenge is large. Africa’s population is projected to double by 2050,” says Barry MacColl , a senior regional manager at the Electric Power Research Institute (EPRI), who covers Africa from Johannesburg. “Expanding national grids can be expensive and slow, especially in rural and remote areas, where most of the unelectrified people live.” For example, South Africa’s main utility, Eskom Holdings, estimates it will need to spend 390 billion rand (US $22 billion) over the next decade to expand and upgrade its aging power grid and prevent future blackouts . Large differences in electricity access persist among and within African countries. According to a 2020 report from Germany’s Federal Ministry for Economic Cooperation and Development , in the East, West, and Southern African regions, about half the people have access to electricity, but the percentage falls to a mere 30 percent in Central Africa, where nearly 100 million folks have no electricity access . And according to the World Bank , about 82 percent of urban residents had electricity access in 2023, but only 33 percent in rural areas. (The North African countries aren’t part of the sub-Saharan region, and, except for Libya, have electrification rates of 100 percent.) Off-grid solar’s untapped potential in Africa Fossil fuels still play a big role in Africa’s power generation. Natural gas is the single largest source of electricity generation, while coal is significant only in South Africa. Together, they account for roughly two-thirds of the continent’s electricity production, according to BloombergNEF. While new gas-fired plants continue to be built, the trend is shifting toward renewable energy sources. An electronics shop in Kenya sells solar panels. Off-grid solar has been a big part of the country’s successful push to increase electricity access. James Wakibia/SOPA Images/LightRocket/Getty Images Small-scale off-grid technologies, especially solar power, are widely viewed as the strongest path to expanding electricity access to rural communities and underserved urban areas. UNCTAD estimates that Africa has 60 percent of the world’s best global solar resources. That translates to a solar potential of over 10 terawatts. “Off-grid solar and storage is taking off in a big way,” says Sonia Dunlop , CEO of the Global Solar Council in London. “There are already about 600 million people, almost all in sub-Saharan Africa, who use off-grid solar and storage at least once a week.” Dunlop expects to see a 40 percent increase in solar installations next year in the region. Off-grid solar power lends itself to bottom-up bootstrapping in rural areas by communities, small farms, businesses, and residential customers. To make the technology more affordable, the expansion of microfinancing will be key, as Mwoya Byaro and Nanzia Florent Mmbaga point out in a 2022 study in Scientific African . RELATED: Off-Grid Solar’s Killer App I know firsthand the difference off-grid solar can make. My Nigerian-born wife and I own a walled compound of three homes in southern Nigeria, where members of her family live. We recently installed solar lights atop 5-meter-tall poles. They now illuminate communal areas that were formerly dark at night. The compound and the neighborhood aren’t connected to the grid, though, so for indoor electricity, our relatives still rely on diesel generators. The future of hydropower in sub-Saharan Africa While off-grid solar could bring electricity to millions of people, hydropower is “Africa’s renewable-electricity powerhouse, largely thanks to excellent resources in the East and Central regions of the continent,” BloombergNEF reported in 2024 . Six countries, led by Ethiopia, get most of their electricity from hydropower. Engineers monitor the Kariba Dam, on the Zambia-Zimbabwe border. Hydropower could play a big role in expanding electricity access in sub-Saharan Africa, but construction is expensive and changing rainfall patterns are making hydropower output unpredictable. The Washington Post/Getty Images “The hydro space is a huge growth area target,” says MacColl of EPRI. As with solar, Africa uses only a small fraction of its hydropower potential. Mini hydropower dams from 100 kilowatts to 1 megawatt are important for remote and small communities of around 50 to 500 homes, MacColl says. Large dams are under construction or have been recently completed in Angola, Ethiopia, Nigeria, and Zambia. But constructing hydropower dams is costly and carries the risk of corruption and mismanagement that comes with big projects, as well as the cost of connecting a new power source to the power grid. For instance, Nigeria’s $5.8 billion, 3,050-MW Mambilla dam , which will become the largest source of electricity in the country, has been in the planning stage for over 40 years, and completion isn’t expected before 2030. Climate change’s impact on rainfall and temperature is also upending estimates of how much electricity hydropower dams across the region can produce. Could nuclear power help electrify Africa? Even nuclear power may play a role in closing Africa’s electricity gap. The African Energy Chamber , an industry group based in Johannesburg, notes in its 2025 Outlook Report that “a significant number of countries in Africa are considering embarking on nuclear power programmes.” Today, only South Africa has nuclear power. But Ghana, which runs a research reactor , is planning its first nuclear power plant with assistance from China, Japan, and the United States. Uganda has chosen a site for its first reactors, as has Kenya. And the Nigerian Nuclear Regulatory Authority says it has signed technical agreements on nuclear power with France, India, Russia, and South Korea. But in all these cases, generating electricity from nuclear power is at least a decade away, according to the World Nuclear Association. Kenya’s electrification success story Ultimately, increased access to electricity in sub-Saharan Africa will come from a variety of sources. One success story is Kenya, where off-grid electricity, primarily from solar, is complementing expanded grid access. The government’s Last Mile Connectivity Project aims to extend the grid to an additional 280,000 residences, 30,000 businesses, and health centers and schools in all 47 counties, according to the African Development Bank, which helped fund the effort. Previously, the national utility, Kenya Power, succeeded in increasing the number of grid-connected households in the poorest urban areas from 3,000 to 150,000. Kenya also has the largest wind farm in Africa, the Lake Turkana Wind Power Project . The 310-MW plant’s 365 turbines account for about 15 percent of Kenya’s installed electricity capacity. These sustained efforts doubled Kenya’s electrification access rate between 2013 and 2023 to 79 percent. Kenya Power now aims to achieve universal electricity access by 2030 . Meanwhile, in Nigeria, the most populous sub-Saharan country, the outlook for electricity access is cloudier. Joe, the Nigerian rice farmer, is considering installing more solar on his farm, to expand his mill. With more electricity, he says, “we can grow more rice, and mill and bag more for our people.” If the power grid won’t—or can’t—come to him, at least he has the means to generate his own electricity to meet his own needs.",
    "published": "Fri, 15 Aug 2025 14:05:36 +0000",
    "author": "G. Pascal Zachary",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Power Grid Congestion Is a Problem. Here’s a Solution",
    "link": "https://spectrum.ieee.org/dynamic-line-rating-grid-congestion",
    "summary": "On a cloudy day in mid-July, a crew of technicians carries a shiny metal orb, about the size and weight of a kid’s bowling ball, under a 110-kilovolt transmission line running near Hamburg. Their task: to attach the orb to the line where it will track real-time environmental conditions affecting the capacity of the wire. To hoist the orb onto the overhead line, a crew member attaches it to a quadcopter drone and pilots it up with a remote control. As it nears the wire, one side of the orb slides open, like a real-life Pac-Man about to chomp a power pellet, and then clamps down. The process takes about 10 seconds and requires no electrical downtime. Oslo-based Heimdall Power , the manufacturer of the orb, has installed over 200 of them on the transmission lines of SH-Netz , the grid operator in the northernmost part of Germany . Together, the devices form a system that calculates how much current these high-voltage lines can safely carry based on real-time weather conditions. The hotter it is, the lower their capacity. Historically, grid operators have estimated the capacity of lines based on average seasonal temperatures—a fixed value called static line rating. For safety, the estimates must be highly conservative and assume that the weather is always very warm for the respective season. So for all but the hottest days, transmission lines could carry significantly more electricity, if grid operators only knew the actual temperature of the wires. Tools like Heimdall’s orb, dubbed the Neuron, can fill in that blank. By tracking information such as the sag of the line and ambient temperature, the system can more accurately determine the temperature—and therefore the real-time capacity—of the line. This allows grid operators to take advantage of the unused headroom by maximizing the current in that line. The system uses weather forecasts to predict the temperature and capacity of the lines for the next day, which is especially useful for day-ahead planning. Dynamic Line Rating Offers Grid-Congestion Solution The strategy, called dynamic line rating , or DLR, is being rapidly adopted in North America and Europe as an antidote—at least in the short term—to grid congestion woes. New transmission lines are needed to accommodate the explosion of AI data centers, electrification, and renewable energy generation, but building them is a notoriously lengthy task often requiring a decade or more. In the interim, grid operators must do more with existing infrastructure. Dynamic line rating and other grid-enhancing technologies, or GETs, offer a quick and inexpensive fix—a bridge until new transmission can be built. Heimdall is one of many companies, including Linevision in Boston and Gridraven in Tallinn, Estonia, providing the technology. “Transmission operators aren’t maximizing the potential of our power lines, leading to unnecessarily high energy costs for consumers,” said Caitlin Marquis , managing director at Advanced Energy United , an industry advocacy group, in a statement . “Dynamic line ratings are one of the most cost-effective tools we have for getting more out of our existing power-grid infrastructure.” Heimdall Power’s orb tracks line sag, ambient temperature, sunlight intensity, and other metrics on a transmission line in southwestern Norway. Heimdall Power Heimdall’s Grid-Enhancing Technologies In Heimdall’s approach , one of the key metrics its sensors track is line sag; as metal wires get hotter, they expand and make the line droop. Measuring sag helps determine how much capacity drops. The sensors also track other information such as ambient temperature and sunlight intensity. Heimdall combines the information with local weather-forecast data—particularly wind speed, which has a cooling effect on power lines and can thus increase their capacity. Heimdall’s machine learning uses the data to help grid operators plan how they’ll route electricity for the next day. In urgent situations, they can use real-time data from its sensors to adapt on the fly. After working mostly with utilities in Europe, last year the company opened a headquarters in Charlotte, N.C., to better access the U.S. market. Its first major U.S. project , in Minnesota, is helping the utility Great River Energy increase its capacity by 25 percent nearly 70 percent of the time, according to the utility. Heimdall has deals with six additional U.S. utilities bringing its technology to 13 states. “We’ve spent the last 80-plus years building the North American power grid, and we’re basically still running it the way we did in the beginning,” says Heimdall U.S. President Brita Formato . “DLR lets us bring the existing grid into the digital age—essentially overnight, and with relatively low cost and effort.” Linevision’s Lidar Sensors Enhance Power-Line Monitoring Linevision, another dynamic line rating provider, uses lidar sensors to monitor line sag, and combines the data with weather forecasting and computer analysis of how wind is affected by objects near power lines. Instead of putting its sensors directly on the power lines, the company mounts them on the towers. This makes installation and operation easier, according to Linevision. The company originally used electromagnetic sensors to indirectly measure loading on each line but pivoted to lidar as it became cheaper and more widely deployed in self-driving cars. “When we made that switch, we were riding the wave of autonomous vehicles,” says Jon Marmillo , Linevision’s cofounder and chief business officer. Linevision’s LUX sensor uses lidar to monitor line sag and is installed on transmission line towers. Linevision For the wind prediction, Linevision starts with a detailed, publicly available spatial map that includes buildings and trees, then uses machine learning to interpret how obstructions change wind near power lines. Marmillo says it takes about 90 days of learning for the system to create accurate predictions of line capacities after it’s installed. Utilities then integrate that into their grid-management software. After completing an earlier project with Linevision, National Grid, the grid operator for England and Wales, in June announced a new, bigger project with the company, on 263 kilometers of 400-kV lines. The first project increased capacity by 31 percent on average, freeing lines to carry an additional gigawatt of power and saving customers £14 million annually (US $19 million). The new project is expected to save customers £20 million annually ($27 million). Gridraven’s Wind Forecasting Boosts Dynamic Line Rating In Estonia , DLR provider Gridraven takes a different tack: It doesn’t use hardware at all. Instead, it relies on machine learning to make accurate, hyperlocal wind predictions. The predictions are based on weather forecasts and a detailed terrain map made from satellite and lidar scans. Georg Rute , the CEO and cofounder, was working for Estonia’s national grid operator in 2018 when he noticed that forecasts of wind around power lines were “really bad,” he says. Rute came back to study the question in 2023 with Gridraven’s other two cofounders, finding that two-thirds of the error in wind prediction was caused by the landscape—mainly buildings and trees. Gridraven’s CEO, Georg Rute, founded the company after realizing that hyperlocal wind forecasting wasn’t accurate enough for dynamic line rating. Gridraven Gridraven began its first large rollout last month, covering 700 km of Finland’s 400-kV lines , and plans to expand to the country’s entire 5,500-km network of high-voltage transmission lines. “With DLR, it is particularly possible to support the integration of wind power into the grid,” said Arto Pahkin , a manager at Fingrid , Finland’s transmission system operator. “This makes DLR a strategically important part of the integration of renewable energy.” Gridraven’s system can increase capacity of power lines by 30 percent on average, according to the company. DLR companies are quick to point out that the technology is not a cure for all that ails our grids; over the long term, we will simply need more transmission. Congestion is already raising electricity prices and increasing outages. Since 2021, grid congestion has cost American consumers $12–$21 billion per year , depending on electricity prices and weather. Other grid-enhancing technologies can help in the meantime. For example, reconductoring existing lines with advanced materials can double their capacity. But that approach also takes the lines out of use while the new materials are installed, and it’s more expensive than DLR. “The potential of DLR is to unlock up to one-third more capacity in the existing grid globally,” said Rute. “This would boost economic growth and increase affordability right away while more grid is being built.” This article appears in the October 2025 print issue as “Grid Operators Squeeze More Capacity From Their Lines.”",
    "published": "Wed, 13 Aug 2025 12:00:03 +0000",
    "author": "Amos Zeeberg",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Is Your Energy System Built to Handle the Next Disruption?",
    "link": "https://process.honeywell.com/us/en/industries/renewable-and-energy-storage-solutions/c-and-i/control-and-energy-management/white-paper?utm_source=3rdparty&utm_medium=email&utm_campaign=25-q3-ia-hps-pas-ww-bess-controlenergymanagement&utm_content=partner-wiley-ieee-controlandenergymgt-wpaper",
    "summary": "Discover how integrated control of microgrids, storage, and renewables prevents downtime, cuts costs, and future-proofs your operations. Leverage Honeywell’s software to monitor and control energy generation and storage assets to improve business resilience, increase renewable energy use, and reduce operating and energy costs. Track historic, current and predicted energy management asset performance and energy use over single or multiple operating sites. What Attendees will Learn How to reduce peak demand charges through automated peak shaving Strategies to balance mixed energy sources (solar, storage, grid) without disruption Ways to turn energy assets into revenue streams via market participation Real-world proof : How Honeywell’s Lugoj plant cut grid costs by 30% while ensuring backup power Download this free whitepaper now!",
    "published": "Tue, 12 Aug 2025 14:49:01 +0000",
    "author": "Honeywell",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Solar Panel Design Concentrates Sunlight for More Power",
    "link": "https://spectrum.ieee.org/solar-panels-micro-cpv",
    "summary": "The sun’s energy can be increased when focused on a smaller area—just ask any kid who has burned holes in a sheet of paper with a magnifying glass. The same concept has been used for small camping stoves and enormous solar furnaces . And while solar panels that take advantage of concentrated sunlight to boost their power output already exist, scientists at the Fraunhofer Institute for Solar Energy Systems (Fraunhofer ISE) in Freiburg, Germany, have taken the concept to a whole new level: They’ve created a micro-concentrated photovoltaic (micro-CPV) solar panel that has better efficiency but lower costs to manufacture. Previous micro-CPV designs have faced multiple problems, including degradation over time and discoloration of the optical elements. Other designs often also required active thermal management systems to cool the components. Innovative Micro-CPV Solar Panel Design The team built a sub-module panel of about 200 square centimeters; while this comprised more than one micro-CPV cell in a 10-by-6 cell array, it was smaller than a standard commercial panel. Often, projects like this require sophisticated processes and expensive materials such as complex lenses and designs that required custom assembly procedures with precision alignment of the elements, but that’s not true in this case. Instead, the researchers used glass substrates for their printed circuit boards. The photovoltaic modules can be assembled using a standard high-speed pick-and-place machine . And the concentrating lenses are made using silicon on glass technology. The researchers estimate that their design uses less than one-thousandth the expensive semiconductor materials required by standard panels. They describe their work in a recent paper published in the IEEE Journal of Photovoltaics . The system relies on planoconvex lenses to focus sunlight. The convex portion is made from silicone, which is a low-cost material with sufficient optical qualities. This is adhered to a flat glass surface, which has matching thermal expansion characteristics to maintain optical alignment throughout temperature changes. The researchers first created a single cell unit using submillimeter-sized photovoltaic chips that measure 885 by 685 micrometers, with an active area of 585 by 585 µm. They then made a larger array module for testing. The matrix array used cells with chips that were 1,127 by 927 µm with an active area of 827 by 827 µm. The larger chip size meant that their placement was less critical than with the smaller chips, which makes assembly easier and more efficient. The chips use five-junction solar cells, which use multiple layers to capture the energy from different wavelengths of sunlight. The prototype micro-CPV solar panel uses a matrix of cells to create an industry-standard 24-by-18 inch panel (61 by 45.7 centimeters) with an aperture area greater than 2,000 square centimeters. Fraunhofer ISE In both cases, the chips were mounted on a glass substrate, which helped dissipate the heat from the panel. This was sufficient to control temperatures without the need for additional active cooling components, in spite of the concentrated sunlight. The outdoor tests were conducted with the panel mounted on a dual-axis tracking mechanism so that the lenses could reliably focus the direct sunlight. “The combination of miniaturized components, additive manufacturing, parallelized processes, and self-alignment promises significant cost reduction for CPV, and will further benefit from learning curves in other major industries. At the same time, energy and resource consumption are cut down,” says Henning Helmers , the head of Fraunhofer ISE’s III-V Photovoltaics and Concentrator Technology department. This could lead to lower environmental impact across the entire life cycle, compared with other photovoltaic solutions. The end result is a more efficient solar panel that can be made from low-cost materials with fewer semiconductor components using standard high-volume manufacturing processes already in use in the display industry. Not everyone is convinced about the economics of the design, however. Jenny Chase, solar analyst with BloombergNEF, points out that “semiconductor materials are inexpensive these days, and dual-axis tracking adds a lot of cost” to an installation. The team tested the panel outdoors over the span of a year. The panel achieved 36 percent conversion efficiency under concentrator standard testing conditions (CSTC) that control for factors that can impact the results, including irradiance (the amount of sunlight reaching the panel), ambient temperature, and windspeed. The tests resulted in median values of 31.4 percent to 33.6 percent conversion efficiency in real-wor l d conditions. According to various sources, the best commercial panels currently available typically have 19 percent to 24 percent conversion efficiency, so this new design extracts about 50 percent more power from the sun. After the year-long test, the team did not observe any significant degradation in the panel or its performance. The micro-CPV development could lead to commercially available panels that cost less to build yet produce more energy, which would make solar power even more attractive as an alternative to other sources. The Fraunhofer ISE team is currently spinning out a company, Clearsun Energy , to bring this technology to market.",
    "published": "Wed, 06 Aug 2025 15:47:43 +0000",
    "author": "Alfred Poor",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Walmart Will Test a Green-Hydrogen Fuel Cell Truck in Chile",
    "link": "https://spectrum.ieee.org/hydrogen-fuel-cell-walmart-chile",
    "summary": "UPDATE 16 SEPTEMBER, 2025: Walmart Chile says their testing trials for the fuel cell truck will begin in November, instead of September as originally planned. —IEEE Spectrum Original article from 6 August, 2025 follows: Latin America’s first green-hydrogen-powered fuel cell truck has hit the road in Chile, marking a milestone for the country’s decarbonization efforts . The semitrailer truck will begin a yearlong testing phase in September 2025, loading up at Walmart Chile’s Quilicura Distribution Center and carrying out operations and deliveries throughout the greater Santiago metropolitan area. Data collected from the testing phase will provide a road map for Walmart and its partners to scale up hydrogen fuel cell trucks across Chile. But as Walmart and the rest of the country work to meet their decarbonization goals over the next decade, the challenge lies in building the necessary infrastructure to support hydrogen-powered ground transport in a geographically challenging environment. Green-Hydrogen Infrastructure Challenges Though Chile’s abundant wind and solar resources make it a prime location for producing green hydrogen , the country has yet to develop the national network of technical operators and fueling stations it will need to overhaul ground transportation with fuel-cell trucks. Two years ago, Walmart Chile’s Quilicura Distribution Center became the first distribution plant in Latin America to produce green hydrogen and operate with hydrogen fuel cell vehicles. That US $15 million initiative involved swapping 200 lead-acid battery-powered forklifts for hydrogen fuel cell versions. Now, that distribution center has the capacity to produce enough green hydrogen to refuel the new truck twice daily, says Ignacio Gómez , Walmart Chile’s supply-chain innovation and technology manager. [Editor’s note: The author conducted an interview with Gómez in Spanish and has provided translations for this story.] The truck, manufactured by Feichi Technology , based in Foshan, China, was purchased as part of a $6.15 million public-private partnership called the Hidrohaul Technological Program . Hidrohaul launched in 2024 as a four-year project to advance hydrogen-powered fuel cell vehicles by bringing together key government and industry players. Chile’s Production Development Corporation put up $3.45 million in funding for the program. Globally, Walmart has committed to decarbonizing operations by 2040, with transportation as a major part of its sustainable distribution strategy, says Gómez. “Hidrohaul is taking the first steps of this strategy by letting us test the country’s first green-hydrogen truck under real-life conditions,” says Gómez. “It’s allowing us to gather lessons learned in order to subsequently scale up this technology .” The truck has an expected range of 750 kilometers and can pull 49 tonnes while holding 75 kilograms of hydrogen fuel. But “no truck is ever going to pull into the station empty,” says Lewis Fulton , the director of the Energy Futures Program of the Institute of Transportation Studies at the University of California, Davis. To be on the safe side, Fulton says long-haul truckers typically avoid dipping below a quarter tank’s worth of fuel. That puts the practical range for the Feichi truck at around 560 km. Chile spans more than 4,200 km north to south, and Walmart operates nearly 400 stores across the country under several subsidiaries. The remote southern region of Punta Arenas is home to the company’s southernmost store in the world and is located nearly 3,000 km from Quilicura, which is currently the truck’s only refueling source. Despite the company’s plans to expand green-hydrogen production to all of its soon-to-be nine distribution centers throughout the country, most of the network, including Punta Arenas, is still out of range. The calculus that determines where hydrogen refueling stations should go changes based on the number of trucks, the capacity of each refueling center, and how far the trucks regularly have to travel to deliver their payloads. In California, Fulton and his team of researchers determined that 15 to 20 refueling stations spread across the state would offer both the geographic coverage and quantity of hydrogen to handle 5,000 heavy-duty trucks. The state leads the United States in fuel cell vehicle deployment . From north to south, Chile is about four times as long as the state of California. Gómez says Walmart is considering installing at least four hydrogen-fuel dispensers at its distribution centers to provide sufficient fuel capacity. At least to start, the truck will remain in central Chile to carry out its test routes. “The plan is for the trucks to carry real merchandise loads from the Quilicura Distribution Center and supply stores within the Metropolitan, Valparaíso, and O’Higgins regions,” Gómez says. Global Deployment of Hydrogen Trucks Chile joins a handful of other countries who have deployed hydrogen fuel cell trucks for long-haul trucking, including the United States, China, South Korea, Japan, and several members of the European Union. China leads the pack in terms of hydrogen fuel cell vehicles, with a targeted 25,000 expected on the roads by the end of this year, according to the Chinese government. That figure is still a relatively small share of the total heavy-duty vehicles operating in the Chinese market. Globally, high costs have limited the deployment of green-hydrogen-powered fuel cell trucks at the industrial scale. While Chile may fare better on this front than the United States and other European countries, in part because of its relationship with China , the country’s mountainous and remote terrain poses a unique hurdle for truck performance. “Hills are a big thing,” says Timothy Lipman of the University of California, Berkeley, who works with Fulton on research related to the rollout of fuel cell trucks in California. “If the topography is totally flat, you’re going to get a longer range and need less fuel than if you’re going over really steep hills.” Extreme hot and cold weather can also impact a fuel-cell truck’s battery and reduce efficiency over time, Lipman says. Thus far, Chile has embraced local hydrogen power in its efforts to phase out sales of carbon-emitting heavy-duty vehicles by 2045 . Yet as the country invests more resources into scaling up its green hydrogen market, Fulton notes that other low emissions technologies, like electric batteries, may become less feasible. “You can only concentrate on so many technologies,” Fulton says. “So if a country or a state makes a strong commitment to one or two technologies, eventually, maybe it gets harder to think about other ones.” This article appears in the October 2025 print issue as “Walmart Tests Fuel Cell Truck in Chile.”",
    "published": "Wed, 06 Aug 2025 13:00:04 +0000",
    "author": "Julia Tilton",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "DOE Has a Crazy-Short Deadline to Pick a Site for New Nuclear",
    "link": "https://spectrum.ieee.org/doe-advanced-nuclear-site-permit",
    "summary": "U.S. president Donald Trump issued a suite of directives in May aimed at hastening the development of advanced nuclear reactors. The directives, delivered via a set of four executive orders, set ambitious goals, such as having 10 new large reactors under construction by 2030, and overhauling the U.S. Nuclear Regulatory Commission (NRC). One particularly eager provision instructs the U.S. Department of Energy to designate, within 90 days, at least one site on DOE-controlled land for the deployment of an advanced nuclear reactor—a nearly impossible deadline that’s coming up August 21. The orders sparked a flurry of discussion across the nuclear industry and sent stakeholders scrambling. Experts weighed the promise of accelerated nuclear deployments against the potential of losing regulatory integrity. Whether the U.S. government, military, and industry stakeholders can meet the demands of the directives and timelines is unclear. As someone with deep expertise in nuclear project development and licensing, I’ve chosen to focus this article on the 90-day site-selection directive—perhaps the first litmus test to see if the Trump administration will execute on its challenging deadlines. The process for selecting a site for a new nuclear plant in the United States is an arduous and complex process that blends engineering feasibility, environmental science, safety, emergency planning, economics, and public trust, all while complying with regulations and guidance. It’s never been done in 90 days, at least not with regulatory approval. But there might be one way for the DOE to meet that deadline: Rely on sites that are already deeply prepared with existing documentation and few unknowns. There are two locations in the United States that come close to fitting this category: Idaho National Laboratory and Oak Ridge National Laboratory . How to Pick a Site for an Advanced Nuclear Reactor To host a commercial nuclear reactor in the United States, a site must first receive a license from the NRC. To get that license, reactor owners typically take a couple of years to prepare the application, 6 to 12 months of which is needed to perform and document the site-selection process. The regulator then reviews the application and performs an environmental impact statement (EIS)—a process that historically took more than two years, but is now required to be completed in 18 months, per new directives . The first step in selecting a site is to identify the region of interest. Next, unsuitable or problematic parts of that region, such as those that are prone to earthquakes, flooding, or landslides, are eliminated. Remaining areas of land in the region are then assessed for technical and environmental suitability. For a small modular reactor (SMR), a type of advanced nuclear reactor, an ideal site size is a couple of hundred acres (about 80 hectares), while a thousand acres (over 400 ha) is ideal for a large nuclear plant. Reactors also need sufficient cooling water, which typically comes from a nearby ocean, lake, river, or aquafer. RELATED: U.S. Pushes $900 Million for Small Modular Reactor Developers must assess the nearby population and infrastructure, search for endangered species, and assess wetlands. Business factors are also considered, such as distance to interconnection with transmission, cost to install and operate cooling, and the amount of site grading needed. Finally, applicants assign weighting values to the criteria and rate sites against the various parameters. This iterative process, followed by further field investigations and narrowing of options, leads to the selection of one preferred site, with two to four others defined as alternatives. After that, the NRC reviews the application and proceeds with the environmental impact statement process. DOE’s Looming Site-Selection Deadline It’s unclear how far along the DOE is in its attempt to comply with the executive order’s 90-day challenge to pick a site for a nuclear plant. Meeting the deadline will require creative thinking and decisive action. With that in mind, the best path forward for the DOE is to focus on sites that have already undergone National Environmental Policy Act review and some NRC licensing. The DOE’s Idaho National Laboratory (INL) in Idaho Falls, and Oak Ridge National Laboratory (ORNL) in Tennessee, both meet those criteria. Near INL, there are two options: the site where NuScale Power and Utah Associated Municipal Power Systems were pursuing an NRC license for an SMR facility before abandoning the project in November 2023, and the site proposed for the Eagle Rock uranium enrichment facility that received a license in 2011 but was not constructed. INL has hosted 52 reactors since 1949 , so it’s likely a suitable place from an environmental and safety perspective. Although both the NuScale and Eagle Rock sites meet the intent of the executive order, neither received an environmental impact statement from the NRC for a new nuclear reactor. Further, the Eagle Rock site is adjacent to INL, not on its site. Perhaps the ideal choice is the 935-acre (378-ha) parcel of land on a peninsula on the Clinch River in Tennessee, adjacent to ORNL. The site is federally owned, currently controlled by the Tennessee Valley Authority (TVA) and is the only site in the United States that has received a green light—an early site permit from the NRC—for SMRs. The Clinch River site was partially developed in the 1970s for the Clinch River Breeder Reactor project, a liquid-metal fast breeder reactor that was abandoned in the early 1980s. The NRC in 2019 licensed the site to TVA for the construction and operation of two or more SMRs. This permit allows for up to 800 megawatts electric (MWe) of nuclear power and followed a thorough environmental and safety review that remains valid through 2039. A small modular reactor called the BWRX-300, developed by GE Vernova Hitachi Nuclear Energy, is planned for the Tennessee Valley Authority’s Clinch River site. TVA In May this year, TVA requested a construction permit to build on that site an SMR called the BWRX-300 , a boiling-water reactor, which would have a capacity of 300 MWe. But the site can accommodate additional SMRs and other advanced or microreactor units, which would fulfill the executive order’s objectives. Clinch River Is Ideal for New Nuclear TVA was prescient in its thinking: Its stated objectives for the Clinch River site include powering mission-critical electricity loads for national defense, which aligns with the executive order’s priorities. In fact, TVA’s 2016 application assessed underground transmission lines to serve mission-critical loads on ORNL—a design feature that makes it less susceptible to intentional destructive acts and natural phenomena such as tornadoes. The area already hosts the DOE’s largest electricity user, the Oak Ridge Reservation , which includes ORNL and the Y-12 National Security Complex , where nuclear-weapons components are manufactured and highly enriched uranium is stored and processed. Historically, the region supported the K-25 uranium-enrichment facility, which consumed, until the 1980s, more than 1,000 MWe. Today, the robust power infrastructure built to serve K-25 remains available in Oak Ridge, including redundant 161- and 500-kilovolt transmission lines that transect the Clinch River site. East Tennessee is also home to one of the nation’s deepest and most experienced nuclear workforces, with TVA, DOE, the University of Tennessee, and many private-sector nuclear companies including Centrus Energy , Kairos Power , LIS Technologies , Nano Nuclear Energy , Orano , Standard Nuclear , Type One Energy , and X-Energy , plus numerous smaller suppliers, all calling Oak Ridge home. TVA has not, thus far, catered to data centers—one of the Trump administration’s priorities. But on 24 July the DOE named the Oak Ridge Reservation one of four locations where it will invite private-sector partners to develop cutting-edge AI data-center and energy-generation projects . An adjacent advanced-nuclear plant on the Clinch River site would pair nicely. TVA’s New Nuclear Constraints This rare combination of attributes simply doesn’t exist elsewhere, and makes the Clinch River site the ideal location to try to meet the provisions in the executive orders. But several challenges lie ahead. TVA’s status as a federally owned corporation comes with constraints that impede progress. Namely, a US $30 billion cap on the amount of debt it can take on was bestowed upon it through the TVA Act and hasn’t been increased since 1979. TVA has been accused of moving too slowly in the development of advanced nuclear and SMRs, and Tennessee senators and the president have called for leadership change at the power provider. Successful execution of the directive will require leadership within the Trump administration. It will require TVA to seek creative solutions and overcome its constraints. One option would be to transfer the Clinch River site and its permit from TVA to the DOE. Or perhaps the simplest solution is for the DOE to contract for power in a manner that enables third-party financing of new nuclear capacity, so that the debt doesn’t fall on TVA’s balance sheet. Given the urgency, importance, and magnitude of the challenge of meeting the United States’ growing electricity needs and to accomplish the intent of the executive orders , DOE should designate both INL and ORNL as locations to host new nuclear reactors.",
    "published": "Tue, 05 Aug 2025 14:00:03 +0000",
    "author": "Daniel Stout",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Grid-Scale Battery Stabilizes Scottish Power Supply",
    "link": "https://spectrum.ieee.org/grid-scale-battery-scotland",
    "summary": "A grid-scale battery in the Scottish Highlands got a chance to prove its mettle in March when, 11 days after it started up, a massive wood-burning generator in Northern England shut down unexpectedly. Suddenly 1,877 megawatts of supply was missing, causing the 50-hertz frequency of the grid’s alternating current to crash below its 49.8-Hz operating limit in just 8 seconds. But the new 200-MW battery station leapt into action within milliseconds, releasing extra power to help arrest the frequency collapse and keep the grid running. Conventional fossil-fuel generators have historically helped thwart these kinds of problems. With the inertia of their spinning rotors, their kinetic energy provides a buffer against rapid swings in frequency and voltage. But the response in the Highlands was one of the world’s first examples of a grid-scale battery commissioned to do this kind of grid-stabilizing job. Without moving parts, the lithium battery storage site—the largest in Europe and located in Blackhillock, Scotland—simulates inertia using power electronics. And in an innovative twist, t he battery site can also provide short-circuit current in response to a fault, just like conventional power generators. Four more of these battery sites are under construction in Scotland. How Do Grid-Forming Inverters Work? The batteries can deliver these stabilizing services thanks to their advanced grid-forming inverters that convert direct current from lithium batteries into alternating current for the grid, and vice versa when the batteries are charging. Rather than “following” the grid’s frequency and voltage the way nearly all other grid-scale inverters do, grid-forming inverters march to their own drum , and can sometimes act faster than conventional generators. “These grid-forming inverters that we’re installing in Scotland—nobody is doing that,” says Julian Leslie , chief engineer and strategic energy planning d irector for the National Energy System Operator (NESO), based in Warwick, England. Andy Hoke , an expert in grid-forming technology and principal engineer at the U.S. National Renewable Energy Lab, says Scotland’s additions definitely push the envelope. “They’re superexciting projects,” says Hoke. Can the U.K. Operate Without Gas Plants? NESO is relying on grid-forming batteries to help achieve an ambitious goal that it set for 2025: to show that the United Kingdom can live without its dextrous, stability-boosting gas-fired plants. The United Kingdom shut down its last coal-fired power plant last year, and by the end of this year NESO plans to demonstrate that it can also operate without gas plants. “By the end of the year we ’ll have a couple of hours with zero-carbon operation, which is going to be amazing,” says Leslie. It would be the world’s largest demonstration of fossil-free grid operation. This is no “eco ego” stunt. Increased stability from power electronics means more solar and wind generators can connect to the grid and minimizes how often NESO must curtail their generation . London-based Zenob ē , the g rid-battery operator behind three of the new Scottish battery sites, estimates that Blackhillock alone will save consumers £309 million (US $418 million) over 15 years. Scotland’s Energy Transition Challenge Scotland is ground zero for the U.K.’s grid-decarbonization challenge. It has already closed not only its coal plants, but also its gas plants. Its one remaining nuclear plant, Torness, will shut down by 2030. With Torness’s closing, the only synchronous generators left in Scotland will be its few remaining small hydropower plants—machines that have for so long maintained the stability of the grid with the mechanical speed of their rotors. The wind- and solar-power installations the country is betting on for its energy future have grid-following inverters that contribute little to grid stability. So solutions are needed. Operators worldwide have been reinforcing their grids by installing synchronous condensers—standalone synchronous generators whose rotors are kept spinning using grid power. Stored kinetic energy is then available when the grid stumbles, much like with a conventional power plant. The Baltic states ordered a raft of these dedicated stabilizers ahead of their recent shift from syncing with Russia’s grid to Europe’s. NESO, however, is taking a different tack in its preparation for zero-carbon operation. Instead of simply specifying synchronous condensers, NESO identified where it needed more stability and invited developers to pitch tech solutions. Grid-forming batteries scored big in NESO’s 2022 tender. The £323 million ($430 million) package of winning bids included Scotland ’s advanced grid-scale batteries along with five synchronous condensers. Short-Circuit Current Innovation What’s most innovative about the grid-forming batteries is that NESO mandated that they provide short-circuit current, just as synchronous generators do. When falling trees and other mishaps connect a transmission line to the ground, short-circuiting the grid, power plants’ synchronous generators release a surge of current that helps prop up voltage . The blast of current is also an important signal that triggers grid-protecting relays to open and isolate the faulted transmission segment in a fraction of a second . Mimicking that behavior is difficult for power electronics. A grid-forming inverter sustains its own voltage and frequency by delivering whatever current is required. When voltage drops, the controller immediately allows more current through the inverter’s transistors. So far so good. But inverters can quickly hit a wall. High currents are like kryptonite for power electronics, producing heat that can quickly fry their transistors. As a result, inverters usually operate at only 10 to 20 percent above their current rating , whereas currents from a synchronous generator can increase 700 percent during a fault. The simplest way to increase current capacity is to add more transistors , but that’s pricey for the insulated-gate bipolar t ransistors used in transmission-level converters. German inverter producer SMA Solar Technology , which supplied Blackhillock’s inverter, found a cheaper way to meet the need, taking advantage of the brevity of short-circuit current. It programmed Blackhillock ’s inverter to hit 250 percent above nominal current to deliver the 140-millisecond pulse that NESO requires, says Aaron Gerdemann , a business-development manager for SMA. After that, the device will back down, allowing the circuits to cool. Can Power Electronics Stabilize the Grid? Zenob ē’s global director of network i nfrastructure, Semih Oztreves , predicts that grid-forming batteries will ultimately corner the stability market thanks to their inherent multifunctionality. While synchronous condensers mostly sit idle, waiting for a rare grid fault, Zenob ē’s advanced batteries earn daily revenue by doing what most other storage sites do. For example, they arbitrage energy, absorbing power when it’s cheap and selling when supplies get tight. But the short-circuit chops of grid-forming batteries haven’t yet faced a real-life test. Until then, doubts linger about whether transmission relays will respond appropriately to the inverters’ digitally defined surge of current . In a report last year for Australian grid operator Transgrid , one expert advised against overreliance on grid-forming inverters for short-circuit current, saying that it would carry “high to very high risk.” The utility later announced 10 synchronous condensers and 5 grid-forming batteries to bolster its grid. So for now, with the stakes high, keeping a few of the pricier synchronous condensers in the mix probably makes sense, says Hoke. “It might not be the cost-optimal solution, but it may be the wise solution,” he says.",
    "published": "Mon, 04 Aug 2025 14:00:03 +0000",
    "author": "Peter Fairley",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Silicon Is Coming to Smartphone Batteries for a Big Energy Boost",
    "link": "https://spectrum.ieee.org/enovix-silicon-anode-battery-smartphone",
    "summary": "A novel lithium-ion battery that uses silicon in its anodes may have the highest energy density of any battery currently commercially available. Its manufacturer, Enovix, says it has shipped the new battery to a leading smartphone company for a debut in mobile phones later this year. Many of the lithium-ion batteries that power everything from mobile devices to electric cars use graphite in their anodes. However, for decades, researchers have investigated silicon as a replacement for this graphite. In theory, silicon offers roughly 10 times the energy density of graphite in lithium-ion batteries. “Basically, graphite holds on to lithium using holes in its structure,” says Raj Talluri , CEO of Enovix . “In contrast, with silicon in the anodes—usually a silicon oxide or a silicon carbide—lithium actually chemically combines with the silicon to form a new material. This lets a silicon-based anode hold on to much more lithium than graphite during charging. When the battery discharges, the silicon material goes back to its original state.” One significant problem researchers have faced when using silicon in lithium-ion batteries is that it bulges during charging, breaking the batteries open. “If you put silicon in a small cellphone battery, stacking the anodes and cathodes like a deck of cards, the expansion that you would see from the silicon during charging would generate enough force to lift up a 2,000-pound truck,” Talluri says. Enovix’s Energy Density On 7 July, Enovix launched its AI-1 battery , which it says overcomes silicon’s major swelling problems. Its energy density, exceeding 900 watt-hours per liter in internal tests, is estimated to be roughly 20 percent greater than that of current major smartphone-model batteries, the company says. The company also says the AI-1 battery, which is about 29.3 cubic centimeters large, possesses an energy capacity of 7,350 milliampere-hours, about 70 percent more than that of current major smartphone-model batteries. It also recharges quickly, reaching 20 percent charge in 5 minutes and 50 percent charge in 15 minutes. The strategy that made this new battery possible was using microscopically thin silicon anode strips. “Then you stack the anodes in such a way that they only expand along their thin side,” Talluri says. “This way they only generate 200 pounds of force when they expand, which can be constrained just by holding them in a metal case.” Improving a smartphone’s battery may improve other critical aspects of its performance. “I spent 25 years working on smartphones,” Talluri says. “One reason I moved to Enovix is that processors got faster and faster, and memories got bigger and bigger, but I found that you could not use either at their full performance because the battery would go down too fast. So by solving the battery problem, it can help everyone.” A key application Enovix is targeting is use in AI-powered smartphones. “AI applications have become very prominent on phones, and they demand much more battery life, especially if they don’t want to process data on the cloud because of user privacy issues,” Talluri says. “Our goal is to have an all-day battery life on smartphones, despite them running the latest AI applications.” Other potential applications for the new battery include Internet of Things (IoT) devices and augmented- or virtual-reality (AR or VR) glasses, Talluri says. Enovix is not currently manufacturing batteries for electric vehicles but may license its technology to other companies in the market. “We’re just at the beginning,” Talluri says. “We’re nowhere close to using the full potential of silicon.” This story was updated on 30 July 2025 to correct the estimated energy density of Enovix’s AI-1 battery compared to other smartphone batteries—it is 20 percent higher, not 50 percent.",
    "published": "Wed, 30 Jul 2025 12:00:02 +0000",
    "author": "Charles Q. Choi",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Mobile BESS Powers Remote Heavy Equipment",
    "link": "https://spectrum.ieee.org/mobile-bess",
    "summary": "In June, a fuel delivery to a Johns Hopkins Hospital campus went terribly awry, spilling 2,000 gallons of diesel into Baltimore’s harbor. As the Maryland capital raced to contain the mess, responders discovered a problem: They didn’t have access to reliable power at the waterfront site. Usually in these kinds of situations, responders bring in fossil-fuel generators. But city officials wanted to do better than burning more fuel while cleaning up diesel. So they tracked down Scott Calhoun , chief operating officer of Power Up Connect . The Baltimore-based company has begun to build mobile battery units that can store enough energy to back up an entire hospital or, in this case, energize a harbor cleanup crew. The company is one of several groups developing mobile battery systems to serve large electricity needs. Volvo builds such systems to charge its all-electric excavators, loaders, and other heavy construction equipment. Tesla has trucked in batteries to beef up the performance of its EV Supercharging stations during times of peak demand. The batteries are a mobile version of a battery energy storage system, or BESS. In the past, BESS has been used in stationary locations to store grid-scale electricity to help balance supply and demand, such as storing solar energy so that it can be used at night or storing backup power in case of outages. The improvements to both the chemistry and engineering of lithium-ion batteries has made it possible to move megawatt-level power on the back of a semi truck. The development opens the possibility to commercialize clean, large-scale electricity on the go for applications that previously relied solely on fossil-fuel generators. Why are Automakers Developing Mobile BESS? Power Up Connect got its start, in 2008, providing small power stations that allowed people at concerts or sporting events to recharge their phones. Later, customers began to ask for enough power to support applications like recharging power wheelchairs. Now, the company has scaled up to a trailer that can daisy-chain up to 10 lithium-ion batteries, each with a capacity of 90 kilowatt-hours—slightly bigger than the one that comes in an entry-level Lucid Air electric sedan. Volvo last year began offering all-electric heavy construction equipment such as loaders and excavators that can move earth with the same force as their fossil-fuel-powered competitors. This equipment needs to be charged, of course, and many clients will want to do that on the job site. So Volvo is building mobile BESS solutions to bring charging to the excavators. The know-how for Volvo’s mobile BESS stemmed from the building of its growing line of all-electric semi trucks, which use advanced battery chemistries to pack a remarkable amount of energy into a mobile battery pack, says Darren Tasker , a vice president at Volvo Penta, a division of the automaker that uses the company’s technologies for industrial applications. The improvements to the lithium-ion batteries are due in part to using a nickel cobalt aluminum oxide (NCA) version with aluminum as the cathode. This allowed them to build 90-kWh transportable batteries. According to Tasker, Volvo could easily fit two six-packs of these units onto the back of a semi truck, providing more than a megawatt of power wherever it might be needed. Those batteries can be driven away to a charging depot overnight where they can be recharged, and then brought back to the job site in the morning. After all, Tasker says, “The definition of a construction site is that it is under construction.” Volvo is looking into lithium iron phosphate (LFP) and lithium-sulfer (Li-S) batteries for future use, Tasker says. The Volvo PU500 BESS offers a capacity of 540 kWh and can charge up to 3 heavy-duty trucks or 20 cars daily. AB Volvo Can Mobile BESS Power Remote Industrial Work? This moveable feast of electricity could be useful in a wide range of industries. Forestry operations, for example, move from place to place, often in remote locations lacking power. Mining, too, could benefit enormously from electrification. Running fossil-fuel-powered trucks and equipment underground creates dangerous emissions that must be vented out of a mine. “The need to electrify underground mining machines is pretty strong,” says Tasker. “To have zero emissions underground is a great driver of new technology,” he says. But the power would need to be mobile. Mobile BESS is also an appealing solution for places that struggle to find the hundreds of thousands of dollars needed up front to install an electric charging station. Testing out electrification with trucked-in batteries is less risky than spending six figures to build permanent electrical infrastructure. Volvo has clients that are using mobile charging stations to support electric garbage trucks, forklifts and loaders at ports. As batteries get better and cheaper, consumer EV charging stations can go off grid. This month Tesla plunked down a battery and solar installation to power an off-grid Tesla Supercharger station, located off Interstate 5 in California. The station provides enough electricity for 80-plus EVs at a time. The challenge to mobile BESS makers is cost. Batteries aren’t cheap; Tasker says that in some cases, clients might be paying $1,000 per kilowatt-hour for mobile BESS power. That temporary solution is still cheaper than building a charging station, but the cost must come down for moveable batteries to make sense for more uses. After the diesel spill in Baltimore’s harbor, the city ultimately turned to trusty-but-dirty generators in an effort to get the spill under control quickly. But next time could be different. Baltimore is now in talks with Power Up Connect to use mobile batteries for future emergency response situations, Calhoun says.",
    "published": "Thu, 24 Jul 2025 16:00:03 +0000",
    "author": "Andrew Moseman",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Quantum Batteries Get a Big Storage Time Boost",
    "link": "https://spectrum.ieee.org/quantum-battery-rmit-university",
    "summary": "Quantum batteries can theoretically charge faster and store more energy than conventional batteries—except they tend to lose all of their stored energy in nanoseconds. Now scientists have developed a new prototype quantum battery that can hold onto its energy for 1,000 times as long as previous devices. They hope that the breakthrough will someday lead to quantum batteries that could power portable electronics and small sensors. Quantum physics can often make matter act in surprising ways. Superradiance is a phenomenon in which a group of energetic atoms releases a far more intense pulse of light than they could individually. The reverse of superradiance is also possible— superabsorption , in which atoms cooperate to absorb light better. Recently, scientists have started developing quantum battery prototypes that can take advantage of such quantum effects. For instance, a 2022 study unveiled a superabsorbent device that collects energy more quickly the bigger it gets. However, previous quantum battery prototypes lost energy nearly as quickly as they charged , because the superabsorption in these devices was also coupled with superradiance, leading to extremely fast discharge rates. Extending Quantum Battery Lifespan In a new study, Francesco Campaioli , a vice chancellor’s research fellow at the Royal Melbourne Institute of Technology in Australia, and his colleagues sought to prolong the life of quantum batteries by experimenting with triplet states , the state of electrons in a molecule after they absorb light. The researchers focused on dark triplet states, which are bad at emitting and absorbing light. This means they can store energy longer than their bright counterparts. At the core of the new device are two different layers of material. One layer, which contains the dye Rhodamine 6G , absorbs light very well. It transfers absorbed energy to a layer made of a compound called palladium tetraphenylporphyrin, which stores this energy as dark triplet states. These layers are separated by an inert polymer spacer to help steer their interactions and sandwiched between reflective silver layers that help control how light from a green 514-nanometer laser energizes the device. “Thanks to the dark triplets in the storage layer, the energy stays in the device for roughly 1,000 times longer than it enters the device,” Campaioli says. The improvement might seem minor—the new prototype can store energy for microseconds instead of nanoseconds. Still, “that’s not bad comparatively,” Campaioli says. “It’s the equivalent of having a phone that charges in 30 minutes and runs out of battery after about 20 days if left idle. Not too shabby.” The scientists are collaborating with industry partners to design the next iteration of prototypes. “There is still a lot of work to do to develop these ideas into a technology that could impact everyday life,” Campaioli says. “What matters to me is that we have a clear understanding of the challenges that we need to overcome to make it happen.” The scientists detailed their findings on 23 June in the journal PRX Energy .",
    "published": "Wed, 23 Jul 2025 15:00:03 +0000",
    "author": "Charles Q. Choi",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Geothermal Energy Survives Trump’s Tax Law",
    "link": "https://spectrum.ieee.org/geothermal-energy-big-beautiful-bill",
    "summary": "This article was originally published by Canary Media . Geothermal energy was spared in U.S. president Donald Trump’s sweeping tax and spending law , which made deep cuts to incentives for other forms of clean energy. But developers of the resurgent energy source may still face difficulties due to complex stipulations folded into the new law, among other Trump administration policies. The “ big, beautiful” Republican legislation largely preserves investment and production tax credits for geothermal power plants—as well as battery storage, nuclear, and hydropower projects—established by the Inflation Reduction Act (IRA). Incentives for wind and solar, however, are sharply curtailed , and subsidies for residential clean-energy projects will abruptly end after this year. Geothermal advocates celebrated the outcome for their industry, which they say will be vital to scaling the resource in the United States to meet the nation’s soaring power demand. The sector has attracted a lot of attention in recent years because it can provide carbon-free power around the clock—something solar and wind can’t do—and technological advances are making it possible to deploy geothermal in places that conventional plants can’t go . This “ policy milestone highlights the geothermal industry’s role in fortifying grid resilience and national security,” Vanessa Robertson , director of policy and education for Geothermal Rising, an industry association, said in a statement. “ With certainty in place, we look forward to seeing projects advance and innovative partnerships flourish.” Still, the industry isn’t immune to the broader market challenges created by Trump’s policies, despite its more favorable treatment from Congress. New tariffs on things like steel and aluminum have increased the cost of drilling equipment, heat exchangers, and other key components. A provision in the budget bill aimed at restricting Chinese companies and individuals from accessing tax credits will make it harder for developers to prove compliance, increasing the risk for investors who finance clean-energy projects. “ We’re making an ugly layered cake of barriers to quick and clean project development,” said Advait Arun , a senior associate for energy finance at the Center for Public Enterprise, a nonprofit think tank. Scaling Enhanced Geothermal Systems Geothermal plants, which harness Earth’s heat to generate power, have for decades represented less than 1 percent of the U.S. electricity mix. That’s because conventional plants tend to be viable only when located near natural formations like hot springs, where the heat is easier to reach, but which only occur in a handful of places in the United States. New tools and techniques are emerging that make it possible to put geothermal plants in more parts of the country. The startup Fervo Energy completed the United States’ first “ enhanced geothermal system ” in late 2023 —a 3 . 5 -megawatt pilot plant in Nevada backed by Google. Now, the Houston-based company is building the world’s first large-scale enhanced geothermal plant in Utah’s high desert. Fervo has raised hundreds of millions of dollars in capital to drill dozens of wells for the 500 -MW Cape Station, with the first 100 MW slated to start delivering power to the grid in 2026 . Fervo Energy rig operators connect drills that will plunge underground to access reservoirs of heat in Milford, Utah, in 2023. Ellen Schmidt/AP In June, the startup XGS Energy announced plans to build a 150 -MW next-generation geothermal project in New Mexico by 2030 to support Meta’s data center operations. Meta, which owns Facebook and WhatsApp, signed a similar agreement last year with Sage Geosystems to build 150 MW of geothermal power at an unspecified site east of the Rocky Mountains. The first phase of that project is set to come online in 2027 . Geothermal has long drawn bipartisan support and has so far dodged Trump’s broader attacks on renewable energy. It helps that the new geothermal wave has considerable overlap with the oil and gas industry, sharing the same drilling equipment, workforce, and investors. U.S. Energy Secretary Chris Wright, previously the CEO of a fracking company that invested in Fervo, played an active role during budget negotiations to shield geothermal from sweeping cuts to IRA incentives. Under the new law, geothermal and other baseload clean power sources can qualify for the full 48 E investment tax credit or the 45 Y production tax credit if they begin construction by 2033 , after which the credits will gradually decrease to zero in 2036 . The concrete phaseout schedule differs from the IRA , which allowed more flexibility and could’ve kept the incentives in place for several more years, according to Geothermal Rising. Wind and solar facilities, meanwhile, must either start operating before the end of 2027 or begin construction by next summer to obtain credits. Geothermal heat pumps , which heat and cool buildings, will lose access to residential tax credits after 2025 . Geothermal Energy for Data Centers For next-generation geothermal firms, the tax incentives are crucial to getting the first slate of projects up and running. Developers use the promise of future tax credits as collateral to raise the many millions in financing they need to explore suitable project sites and deploy novel drilling technologies. The credits also help to attract major customers, including tech giants that are looking for a variety of baseload power sources to run their sprawling data centers. “ They help the market to develop,” said Mehdi Yusifov, the director of data centers and AI at Project InnerSpace, a geothermal advocacy group. “ Tax credits of this kind can…help get infrastructure built on a mega scale.” The nuclear reactor at Three Mile Island in Middletown, Penn., can generate over 800 megawatts—a target range for geothermal power producers. George Sheldon/Alamy Yusifov and Nico Enriquez, a principal at Future Ventures, studied the potential cost of serving a “ hyperscale” data center with power from a 1 -gigawatt enhanced geothermal project in a place like the western United States. In a new analysis , they found this novel project could achieve a levelized cost of energy of US $ 119 per megawatt-hour without the investment tax credit—significantly better than estimated costs for nuclear power. With the tax credit, the hypothetical geothermal system could achieve $ 88 per megawatt-hour, which is competitive with the upper range for a fossil-gas power plant. “ It seems like there’s a dam that would break if it could be proven that [geothermal] can produce power anywhere in the range below Three Mile Island,” said Enriquez, referring to the shuttered nuclear plant in Pennsylvania that is expected to restart to serve Microsoft’s growing energy appetite. “ That’s another reason why this investment tax credit is so important, because it makes it possible to have the dam break,” he added. “ And suddenly you can flood the market with these projects that are giving us critical infrastructure.” It’s unclear whether the budget bill will undermine some next-generation projects due to the anti-China provisions attached to these key incentives. The rules, known as “ foreign entity of concern” restrictions, will require companies to scrutinize their supply chains to an unprecedented degree, with potentially onerous and costly legal implications that make it harder for projects to claim incentives. “ It remains to be seen how developers of these really innovative technologies can navigate this, because it’s not going to be the easiest process from here on out,” said Arun of the Center for Public Enterprise. Even as the headwinds swirl, geothermal developers continue to make significant strides to improve their technologies. Both Fervo and the federal Utah Forge initiative have said they’ve dramatically increased drilling speeds and efficiencies in just a handful of years, with Fervo reducing its per-well costs by millions of dollars. For startups, access to tax incentives allows them to get to work to make such advances in the field, Enriquez said. “ There’s an amount we save long-term if we invest upfront in these tax credits, because of the learning curve,” he said. “ If we can maintain [the momentum] for the next five years, I think this industry will be one of the key power sources for the U.S.”",
    "published": "Tue, 22 Jul 2025 14:00:03 +0000",
    "author": "Maria Gallucci",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "AI Serves Up a Better Way to Produce Green Ammonia",
    "link": "https://spectrum.ieee.org/green-ammonia-ai-catalyst",
    "summary": "Beyond its role as the key ingredient in fertilizers that help feed the world’s 8 billion people, ammonia can also act as a hydrogen carrier. When produced cleanly, it could become a versatile enabler of a future green hydrogen economy, because ammonia is easier to transport and store than the hydrogen it contains. The problem is that virtually all of the world’s 200 million metric tons produced yearly are produced in large energy-intensive factories that consume about 2 percent of the world’s total energy and emit a similar share of global CO 2 . But now, researchers at the University of New South Wales Sydney have developed an enhanced way to make green ammonia through electrolysis. The researchers used machine learning to find an innovative catalyst that speeds up the chemical reaction to achieve “a sevenfold improvement in the ammonia production rate,” says Ali Jalili , a senior lecturer at UNSW Sydney and head of the research team. “And at the same time, it is close to 100 percent efficient.” The new catalyst is designed to improve a lab-built prototype method of making ammonia from air and water using renewable energy. A prototype system, developed in 2021 in collaboration with researchers at the University of Sydney, aimed to produce clean ammonia cheaply on a small scale for decentralized use. To commercialize the process, however, the rate of ammonia production needs to be improved, hence the search for an innovative catalyst. To formulate the catalyst, the researchers selected 13 prospective metals from which a combination might improve results. “However, that would have meant testing over 8,000 different combinations,” says Jalili. “And once you get past two or three ingredients, the chemistry becomes too entangled for old-fashioned trial and error.” Machine Learning Boosts Ammonia Production Instead, they turned to machine learning. The researchers wrote a program in Python based on Gaussian-process learning that can detect patterns in small amounts of data. They fed the program characteristics of the metals functioning as catalysts, as well as their own lab data that considered ammonia production rates, costs, long-term stability, and faradaic efficiency , which is the measure of how effectively electrical energy is used to produce a target product. When the AI model ran the data and made a suggestion, the researchers conducted an electrolysis test and provided it with feedback, which generated a batch of new suggestions. Four rounds of testing were sufficient to produce 28 candidate experiments to find how adding or removing elements might significantly affect ammonia production performance. “Running those 28 tests took us less than a week and led straight to an efficient five-metal alloy of iron, bismuth, nickel, tin, and zinc that outperformed every other combination benchmark,” says Jalili. “It greatly reduced discovery time that would have taken months, while improving the process of producing green ammonia sevenfold—exceeding even our most optimistic expectations.” Ammonia is often produced using an electrolyzer to split water molecules and combine the hydrogen with atmospheric nitrogen. A new catalyst discovered in part through an AI system increases the electrolyzer’s efficiency. University of New South Wales Next, the alloy was formed into an electrode for use in the earlier lab-built prototype system. The air-water-ammonia module includes a nanosecond-pulsed plasma reactor, an electrochemical cell—now fitted with the new catalyst—and process optimization tools. Dubbed “lightning in a tube” by Jalili, the plasma reactor uses tiny bursts of electricity to energize air and break apart nitrogen molecules, making them reactive enough to form ammonia. The electrochemical cell, meanwhile, speeds up the chemical process that converts the nitrogen compounds into ammonia. “It’s a hybrid process running on renewable electricity that bridges plasma chemistry and electrochemistry that we developed ourselves,” says Jalili. “Air and water are taken in one end, and from the other side, out comes green ammonia.” He describes the lab module as a self-contained air-to-ammonia factory packed into a standard 6-meter shipping container. With just air and water, and power from a nearby solar array or wind array, a pilot set-up was able to produce between 50 and 100 kilograms of green ammonia a day—enough to make nitrogen fertilizer for roughly 1 to 5 hectares of crop land depending on the crop. “And extra modules can be added like Lego blocks when more capacity is needed,” says Jalili. Outside of lab conditions, however, a pilot module being tested on a farm is connected to the grid for stability, rather than being powered by renewable energy. According to Jalili, it is delivering 0.5 kg a day of nitrogen-based fertilizer derived from ammonia—enough to grow 500 cucumber plants in a season. In addition, a much larger system is in the planning stages and backed by the New South Wales state government and commercial partners. It aims to produce 90 metric tons of nitrogen-based fertilizer from ammonia yearly on a farm and will be powered by a solar energy plant of several megawatts. Jalili is also talking with the Bill Gates Foundation about the possible use of the technology to produce fertilizer in the sub-Sahara. Meanwhile, the researchers are continuing to develop the present system for commercialization. The goal is to shrink the lab set-up down to the size of a suitcase that can produce a couple of kilograms of ammonia a day for under AU $1 million (about US $655,000). Looking further ahead, Jalili points out that ammonia is one of the world’s most produced chemicals, and the industry knows how to liquefy, store, and ship it safely, while the docking points, pipelines, tank, and terminals are all operating today. “Our containerized modules will enable renewable energy-rich regions to make green ammonia in real time, instead of waiting for billion-dollar hydrogen plants and supporting infrastructure to be built,” says Jalili. “And the fuel can be used in three ways: as fertilizers, cracked back into hydrogen for fuel-cell vehicles, or burned in turbines and engines for clean back-up power.”",
    "published": "Mon, 14 Jul 2025 14:00:02 +0000",
    "author": "John Boyd",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "DARPA Sets New Record for Wireless Power Beaming",
    "link": "https://spectrum.ieee.org/darpa-optical-wireless-power",
    "summary": "The United States’ Defense Advanced Research Projects Agency (DARPA) recently achieved a new record in transmitting energy over distance. In tests performed in New Mexico, the Persistent Optical Wireless Energy Relay (POWER) program team recorded over 800 watts of power delivered for about 30 seconds with a laser beam crossing 8.6 kilometers. The greatest distance records previously recorded were 230 watts of average power for 25 seconds at 1.7 km, and an undisclosed amount of power at 3.7 km. The feat wraps up phase one of a three-phase project. RELATED: Practical Power Beaming Gets Real The estimated receiver efficiency, says POWER team leader Paul Jaffe , is around 20 percent. In other studies, some industrial lasers have recorded a wall-plug efficiency higher than 50 percent. Higher receiver efficiencies are achievable, especially with the use of photovoltaic cells optimized for particular wavelengths—whose production is usually costly and time-consuming. This was not the case here, Jaffe says. The team used commercial ready-to-use solar cells placed within a receiver. As it takes in the laser beam, the receiver reflects the infrared radiation from a conical mirror onto the photovoltaic cells—which, in turn, turns that beam into usable electricity. At this stage, the goal, Jaffe says, was not efficiency, but speed. “There’s a number of design decisions that were made in the interest of building something quickly, not efficiently,” he says. And by quickly, they mean a timeline of three months between planning and execution, says Raymond Hoheisel , founder of Teravec Technologies, the company that developed the receiver. “The breakthrough was to prove this technology can be affordable,” he says. While DARPA did not disclose what the total transmission power was, results show the ensuing output energy was about 800 W. “And we managed to succeed in tests with the receiver running over more extended periods of time [longer than the reported 30 seconds],” Hoheisel says. Optical vs. Radio Waves for Power Transmission Many long-distance power-beaming projects focus on radio (or microwave) frequencies—which means using large transmitters to realize a gain in distance traveled. A process called beamforming is essential for such power transmission to work. Paul Mitcheson , a professor in electrical energy conversion in the Imperial College London’s Control and Power Research Group, describes it like this: In broadcast television or radio, the objective is to propagate the signal as widely as possible so that many people can tune in to a given channel. “That’s exactly what you don’t want to do when you’re beaming power,” he says. In this case, the goal is to beam the signal straight into a receiver with as little loss as possible. “So we need a different structure: The antenna needs to have what we call high gain so that it transmits in one specific direction, with a high degree of directionality.” This is the beamforming process that allows our phones to send a signal to a base station instead of broadcasting it everywhere, Mitcheson adds. But still, there are signal losses. In different ways, infrared laser (or optical) beams have an edge over radio frequencies, says Eric Yeatman , vice-principal and head of the College of Science and Engineering at the University of Glasgow. “Compared to radio, laser is much more focusable—you can create a narrow beam [almost] without any spreading [in ideal conditions],” he says. But as optical frequencies still scatter with fog and clouds, microwaves are generally superior for atmospheric transmission, Jaffe says. On the other hand, lasers do not require the large antennas that radio does. In a previous test he was part of at the Naval Research Laboratory, Jaffe says they required a 5-meter transmitter and a 2-meter receiver to send 1.6 kW across 1 km via microwave frequencies. Radio wave wavelengths are much longer than infrared, so beamforming is more difficult. “What you want is a sort of column of waves. [In any given transmission], the output diameter needs to be much larger than the wavelength, and this is what determines whether you can focus something or not,” Yeatman says. Infrared’s shorter wavelengths mean creating a focused beam is much easier. Because of its high precision, long-range reach, and lighter and smaller equipment required to work, laser technologies are more suitable for building an airborne power relay network. “If it doesn’t work with optical, it doesn’t work at all [for DARPA’s goal],” Jaffe says. “Though the idea of transferring power by laser isn’t new, what they did was an impressive achievement,” says Yeatman. Paul Jaffe (in orange) stands with the POWER Receiver Array Demo team around the receiver after achieving a new record for wireless power beaming at the High Energy Laser Systems Test Facility in New Mexico. U.S. Army White Sands Missile Range The record, Jaffe says, came as a surprise, as it was not the team’s objective. And it’s not the project’s only surprise since it began in 2023 . The use of diffractive optics was another of them. People usually think of a mirror or a lens when it comes to redirecting laser beams, Jaffe says. “But one of the things we found is that diffractive optics may be very well suited for this, particularly because they are good at efficiently handling monochromatic wavelengths of light. This was something we didn’t know at the outset and that revealed itself as we moved forward,” he says. Additively manufactured optics with an integrated cooling system were also something that was not on the script when the project started out. The fact that they managed to do it, Jaffe says, “revealed new and intriguing ways to tackle some of the problems that are very likely to have applications far beyond what we’re doing for POWER.”",
    "published": "Sat, 12 Jul 2025 13:00:03 +0000",
    "author": "Meghie Rodrigues",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Chemical Process Produces Critical Battery Metals With No Waste",
    "link": "https://spectrum.ieee.org/nmc-battery-aspiring-materials",
    "summary": "Olivine is a rather unassuming rock. Olive brown to yellow green in color, this hard yet brittle mineral is thought to be the most abundant in Earth’s upper mantle. Chemically, olivine is magnesium iron silicate, though it contains other elements too. Economically, it’s close to worthless . Its limited industrial utility stretches to gemstones, metalworking, ceramics, and occasionally, as a gravel for road construction. At some mining sites, olivine is a waste product, stored in piles on the surface. It’s certainly not an obvious choice as a source for battery materials . But that’s exactly how it’s viewed by a group of New Zealand engineers. Christchurch-based Aspiring Materials has developed a patented chemical process that produces multiple valuable minerals from olivine, leaving no harmful waste behind. Perhaps most interesting to the energy sector is the rarest of its products—hard-to-source nickel-manganese-cobalt hydroxide that is increasingly required for lithium-ion battery production. Sustainable Mineral Extraction Process Aspiring’s pilot plant, which opened in February, is in an anonymous industrial estate east of the city. One corner of the main floor is dominated by a large stainless-steel tank, which is connected to a series of smaller tanks arranged in a stepped line. “Apart from our electrolysis system, the hardware is more typical of dairy plants,” says Colum Rice , Aspiring’s chief commercial officer. “The process is elegant but not massively complicated. Our inputs are rock, water, and renewable energy, and our products come with no CO 2 emissions.” The rock is olivine “flour”; a fine, green-gray dust that is an unwanted by-product from refractory sand production. This is carried by screw conveyer into the largest tank, where it is combined with sulfuric acid. This acid-leaching step “transforms it into kind of an elemental soup,” says Megan Danczyk, lead chemical engineer at Aspiring. From there, it passes down the reaction chain vessels, where through the addition of caustic soda and careful management of particle size and temperature, three products can be individually extracted. Megan Danczyk, Aspiring Materials’ lead chemical engineer, holds a scoop of magnesium hydroxide. Aspiring Minerals About 50 percent of what the process makes is silica that can be a partial replacement for Portland cement , the most common variety of cement in the world. About 40 percent is a magnesium product suitable for use in carbon sequestration, wastewater treatment, and alloy manufacturing, among other things. The final 10 percent is a mixed metal product—iron combined with small quantities of a nickel-manganese-cobalt hydroxide. The battery industry calls it NMC , and it is the go-to material for high-power applications. Danczyk explains that at the end of the extraction process, they’re left only with a salty brine. “This goes to an electrolyzer, which recycles and regenerates the acid we use for digestion and the base we use to separate the products. It’s a closed loop. We’re using the whole rock, and we’re processing it at low temperature and ambient pressure.” Right now, Aspiring does each separation consecutively, or as Rice put it, “silica, reload, NMC, reload, magnesium.” The plan is to add two more reaction chains in parallel, so that the process can run continuously, shortening the runtime from three days to one. NMC Materials in Battery Manufacturing NMC materials are already widely used in battery manufacturing; typically forming the cathode in high-energy-density lithium-ion batteries, or for those electrical systems that need to be frequently cycled, such as power tools, large-scale energy storage , and electric vehicles. “What we’ve been able to produce here matches the specs of what is currently used in the battery space,” says Danczyk. Today, most industrially relevant NMC materials are made by combining salts of their three main ingredients, and each of those regularly appear on critical minerals lists because of their growing importance in our modern world. The challenge with critical minerals is accessing them. Most of the planet’s nickel is sourced and refined in Indonesia . South Africa has the world’s largest manganese reserves, but exports almost all of it to China for processing. For cobalt, the largest producer is the Democratic Republic of the Congo, but again, it is refined in China. Concerns around supply monopoly, geopolitical instability, human rights violations, and environmental damage in these regions have been widely documented. While NMC hydroxide represents the smallest fraction, (about 1 percent) of Aspiring’s outputs, it could still make a dent in future supply chains for battery materials. As Jim Goddin—who sat on the U.K. government’s expert committee that developed the country’s Critical Minerals Strategy in 2023—explains, the approach to securing supplies of these materials is changing. “Economies are looking at how they can shore up supply, and diversify the supply chains, including collaborating with smaller producers who potentially offer more stability. The third branch is the circular economy, which is ensuring that materials they do have are used for longer or recovered for reuse.” Aspiring is not the only company looking to extract more value from already-mined materials. Canadian company Atlas Materials is currently commercializing a similar closed-loop process that produces a similar set of products, but the starting point differs—rather than olivine, it focuses on serpentine. “My understanding is that of these two raw materials, olivine is actually the more difficult to acid leach,” says Fei Wang, an assistant professor at Université Laval in Quebec City. “So that means it needs a higher energy input and will consume the acid more quickly.” Wang’s research also focuses on hydrometallurgical extraction of critical metals, but he is not involved with Atlas or Aspiring. “There’s no doubt that Aspiring’s technology is interesting, and represents a step forward in progress, but I have some concerns around the economics of it,” he adds. For Goddin, the conversation should be broader than that. “From a European perspective, things are shifting towards cleaner, more sustainable production. There’s an increasing focus on providing data about the environmental impacts of the materials that are imported and consumed. Even if, say, Aspiring’s materials ended up being more expensive, they may be able to compete on those grounds. They’re extracting value from every component they produce, and with low to no waste. That’s likely to be a benefit for exporting to those markets.” This article appears in the September 2025 print issue as “ Startup Extracts Critical Battery Metals From Common Mineral .”",
    "published": "Tue, 08 Jul 2025 15:05:01 +0000",
    "author": "Laurie Winkless",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "United States Tackles Nuclear Waste",
    "link": "https://spectrum.ieee.org/nuclear-waste-reprocessing-transmutation",
    "summary": "The United States’ 90,000-ton stockpile of radioactive nuclear waste has long been a liability , but researchers are increasingly eyeing it as a resource. New techniques in transforming spent fuel, new nuclear-fuel-cycle directives from the Trump administration, and the doling out of a Biden-era US $40 million research program together aim to repurpose nuclear waste on a commercial scale. In a suite of executive orders announced on 23 May, U.S. President Donald Trump directed the U.S. Department of Energy to create recommendations for domestic recycling of nuclear waste and identify opportunities to work with the private sector. And in January, the U.S. Advanced Research Projects Agency–Energy (ARPA-E) began awarding $40 million to 11 groups developing transmutation techniques that will reduce the radioactivity and amount of nuclear waste. The funding is part of ARPA-E’s Nuclear Energy Waste Transmutation Optimized Now (NEWTON) program, announced in July 2024 under the Biden Administration, which aims to make recycling the entire U.S. nuclear-fuel stockpile economically viable by the 2050s. The federal support under two administrations has prompted physicists and energy researchers to turn their attention to nuclear waste in an effort to meet the fed’s ambitious goals. “It is technologically possible, but it will take significant investment, and a meaningful commitment from the country, to actually pull it off in 30 years,” says Greg Piefer , CEO at Shine Technologies , a fusion startup that is applying its expertise to nuclear waste. The company, based in Janesville, Wisc., received $4 million from ARPA-E’s NEWTON program. How Is Nuclear Waste Reprocessed? Closing the nuclear fuel cycle involves separating the uranium and plutonium that make up more than 95 percent of nuclear waste, and recycling them back into reactors as fuel. The technology to do this is established, but it is expensive to carry out commercially on a large scale, says Brett Rampal , senior director of nuclear and power strategy at Veriten , an energy research, investing, and strategy firm. There are no technologies that achieve complete uranium and plutonium extraction, so some amount of material is left over from this first step, Rampal says. Orano produces mixed oxide (MOX) fuel after plutonium is remixed with depleted uranium. Eric Larrayadieu/Orano The other 5 percent of nuclear waste, which is composed of long-lived radioactive material, cannot be reused as fuel and has traditionally been set aside to decay over hundreds of thousands of years. It’s the conundrum of what to do with this 5 percent that ARPA-E and several companies are trying to solve. Many groups are approaching the problem by trying to find a cost-effective way to shorten the lifespan of radioactive waste to tens or hundreds of years, through transmutation. “Used fuel is full of good stuff,” says Curtis Roberts , vice president of communications at Orano , a Paris-based nuclear-fuel-cycle company that plans to work with Shine. “People are looking at what was a big pile of waste and going: If I pull this piece out and that piece out, all of these bits and pieces have value in many cases.” “For us, the business case of already having 90,000 tons of this stuff sitting around is pretty solid in and of itself, and then we’re adding about 2,000 tons per year with the current reactor fleet.” Orano and Shine plan to glean value from the long-lived isotopes in the spent-fuel-recycling process and that last 5 percent of the waste that has traditionally been left to decay. Over the last decade, Shine has commercialized technology to separate isotopes for medical applications such as cancer treatment. Now, Piefer is betting that the same strategy can be applied to nuclear waste. In Shine’s technique, neutrons— a side product of its fusion process —are beamed at long-lived isotopes in nuclear waste to break them apart into shorter-lived isotopes. “Neutrons can actually be far more valuable than the energy [from fusion] when applied to certain markets,” Piefer says. The company will separate out valuable isotopes such as Strontium-90, which has fuel applications in marine and aerospace engineering and use neutrons to transmute the rest into shorter-lived isotopes. Molten salt will contain the isotopes to reduce risks associated with remaining radioactivity. The approach can reduce the waste to as low as a fraction of a percent of the overall spent fuel. If successful, Shine would sell the uranium and plutonium it recovers from the bulk of the waste to partners that can turn it into fuel rods to feed nuclear reactors. Piefer’s goal is to operate a pilot plant in the 2030s. “For us, the business case of already having 90,000 tons of this stuff sitting around is pretty solid in and of itself, and then we’re adding about 2,000 tons per year with the current reactor fleet,” he says. Neutrons and Nuclear Fuel Cycle Innovation Because neutrons are essential for transmutation, ARPA-E is also investing in ways to create them. In January, ARPA-E awarded $2.6 million to Oak Ridge National Laboratory , in Tennessee, and a combined $10.2 million to Argonne National Laboratory , in Illinois, to develop particle accelerators for the purpose of generating neutrons. Another NEWTON awardee, Yale University spin-out Omega-P R&D , in New Haven Conn., aims to demonstrate that a compact particle accelerator can work at the lab scale to create neutrons. Called a deuteron Cyclotron Auto-Resonance Accelerator (dCARA), the technology hinges on a cyclical structure that accelerates ions—the ingredients for neutrons—on spiral-like trajectories to create high-energy neutron beams. Compared to conventional particle accelerators, the dCARA version works more efficiently and is much smaller, measuring tens of meters instead of hundreds of meters. It generates fewer neutrons per second per accelerator, but the machines are less expensive to build, say physicists Jay Hirshfield and Yong Jiang , senior and chief scientists at Omega-P, respectively. “That our machines are smaller suggests that they could be sited regionally, for example, near operating reactors and accomplish on a national scale the same degree of transmutation as might be achieved by one larger machine,” says Hirshfield. This strategy reduces risks to the entire transmutation process, Hirshfield says, because issues arising from one accelerator would not compromise the entire supply chain as would be the case for a singular large accelerator. Orano workers observe a crane being lowered into a pool of nuclear-waste containers. Eric Larrayadieu/Orano Nuclear Waste Recycling Trends Researchers in the United States initially developed the ability to separate uranium and plutonium from used nuclear fuel in the 1940s as part of the Manhattan Project . But nuclear-waste recycling stalled during the Cold War and did not rise to commercial scale in the United States. (A commercial facility did operate briefly in New York between 1966 and 1972 to reprocess spent fuel from both government-owned defense and commercial power reactors.) In 1977, U.S. president Jimmy Carter shut down used-fuel reprocessing as an antiproliferation measure, because the plutonium pulled out can be enriched to make weapons. When fuel recycling was opened back up under U.S. president Ronald Reagan, the technology was too expensive to be cost-effective commercially. Today, the calculus has shifted. Trump’s executive order in May calls for an evaluation of the United States’ used-fuel reprocessing practices and has generated a broadly positive response from the nascent industry. The order gives the DOE eight months to report back on recommended policy steps for managing nuclear waste and developing a sustainable long-term fuel cycle with improved recycling processes. The order also calls on the DOE to consider a government-owned, privately operated nuclear-fuel recycling facility. Globally, only a handful of countries also have the capabilities for nuclear-fuel reprocessing, including China, France, Japan, Russia, and the United Kingdom. Those reprocessing facilities handle commercial and defense-related nuclear waste, targeting material that can be separated into uranium and plutonium isotopes. While developments are underway in places such as France, Japan, and Russia to recover other isotopes from waste, such efforts have yet to be commercialized at scale. Currently, waste remaining from fuel recycling is vitrified and then cast in stainless steel or other packaging that can be stored for thousands of years.",
    "published": "Mon, 07 Jul 2025 14:18:34 +0000",
    "author": "Julia Tilton",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  },
  {
    "title": "Cuba’s Power Grid Nears Total Failure",
    "link": "https://spectrum.ieee.org/cuba-energy-crisis",
    "summary": "For many Cubans, the sudden stop of a fan is more than just an annoyance on a tropical island; it’s a daily reminder of a critical, nationwide problem. On an average day, the Cuban government can meet only 50 to 70 percent of its country’s electricity needs. On top of that, Cuba’s entire grid has collapsed four times in the last six months. The problem stems from years of neglect of Cuba’s energy infrastructure, exacerbated by constrained access to foreign capital and a failure to adapt to new energy options. As a result, Cubans are experiencing a significant breakdown in basic services, such as the storage of fresh products, basic food preparation, public lighting, and access to businesses. This has forced citizens to take extraordinary measures, like cooking multiple meals at once and working by flashlight. Cuba isn’t just in an energy crisis; the country’s grid sits on the verge of systemic failure. The National Electric System, most of which was built after 1959, hasn’t received the investment and maintenance it needs for 35 years—a consequence of Cuba’s complex political and economic history. If neglect continues, the island nation will pay the high price of further economic decline, and increased social and political instability. How did my home country get here? Cuba’s Energy Infrastructure Crisis Cuba’s grid infrastructure is so weak that run-of-the-mill problems like transmission line failures and generator trips are causing widespread outages. The unexpected shutdown of the Antonio Guiteras oil-fired power plant started the total blackout in October 2024. Healthy grids should be able to detect and isolate these kinds of issues, and provide backup through built-in redundancies. But Cuba’s old protection systems couldn’t detect the faults, and there weren’t enough spinning reserves to compensate for the generation instability, making recovery impossible. Underlying the blackouts are three systemic problems: years of inadequate investment, substandard fuel, and deferred maintenance. Cuba’s aging thermal power plants—the backbone of the system, nearly all of which run on crude oil or fuel oil—are becoming less reliable, and must operate well below capacity because of fuel shortages and corrosion. One of the biggest, the 330-megawatt Antonio Guiteras plant in Matanzas, often breaks down because there aren’t enough replacement parts to repair it. Other facilities have been hit with adverse events, such the 2022 fires at the Lidio Ramón Pérez (Felton) and Máximo Gómez (Mariel) thermal plants. During the first five months of 2025, only 34 percent of the capacity of all of Cuba’s power plants, based on 2023 numbers, was available on an average daily basis. Cuba’s energy system also suffers from years of reliance on domestic, poor-quality heavy crude oil, which is corrosive because it’s high in sulfur. This has accelerated the wear and tear on boilers, turbines, and pipes in Cuba’s power plants, shortening their life spans and causing frequent and costly outages. Cuba has secured a substantial amount of oil from Venezuela since 2000 through a favorable agreement. But Venezuela’s continuous economic problems have made this outside oil source less reliable, with shipments dwindling in recent years. To help compensate for power deficits, Cuba in 2019 started renting floating thermal power plants from other countries such as Turkey’s Karpowership . By 2023, eight of these kinds of ships were floating in Mariel Bay, Havana Bay, and Santiago de Cuba Bay. But their fate is now just another symptom of the crisis. The government had trouble paying the high leasing prices, so the ships’ operators withdrew from Cuba’s waters, taking hundreds of megawatts with them. Cuba’s Renewable Energy Options Heavy crude oil isn’t Cuba’s only resource; it has a wealth of untapped renewable energy options, including solar, wind, and potentially sugarcane biomass. But the transition to renewables has progressed slowly and somewhat haphazardly , despite ambitious goals set by the government. Crucial renewable energy projects often get delayed due to bureaucratic hurdles and a lack of funding. The instability of the grid makes it more challenging to integrate large-scale renewable energy installations, as they require stable connections to function effectively. And while the country actively seeks solar energy, it’s overlooking its once-thriving sugar sector, and the biomass and ethanol resources that come with it. The Cuban government’s puzzling decision to invest heavily in building expensive hotels and enhancing tourism infrastructure while neglecting necessary grid updates has also made the system more vulnerable. From 2010 and 2024, Cuba spent about 32 percent of total investment on tourism-related infrastructure, and only 12 percent on energy infrastructure, according to Cuba’s National Statistics Office. Cuba’s economy is in a poor state due to the well-established inefficiencies of its economic model and U.S. sanctions that worsened under the first Trump administration and remain largely in place. As a result, the government lacks the necessary hard currency to import gasoline, acquire the spare parts it needs, access the latest technology, and attract significant foreign investment that is essential for upgrading its energy infrastructure. Cuba’s Power Outages and Rationing Breeds Resentment The Cuban government reacts to its severe deficit with striking public ceremony. Every morning, usually between 7:00 and 8:00, officials openly declare the anticipated electricity generation shortfall. Then, provincial leaders across the island painstakingly choose which of their communities will lose power and for how long—on average 19 hours, and some over 24 hours. Daily electricity deficits in Cuba have averaged around 1600 MW in 2025, according to data compiled from daily press releases from Unión Eléctrica (UNE), the state-owned company responsible for Cuba’s electricity system, and news outlets. Data from Cuba’s four recent grid collapses were excluded. Blackouts for these “interruptible circuits,” as provincial electrical companies refer to them, are supposed to rotate based on a schedule. But the actual electricity availability almost always falls short of the plan, so the rotation isn’t carried out as intended. And with certain services and businesses being prioritized for power, a disproportionate share of the outages falls on a portion of customers. Havana, the capital, gets partly shielded from this, due to its political and economic importance. It’s a favoritism that understandably breeds resentment in other areas. But even in Havana, residents on interruptible circuits must contend with at least four hours of power outages every day—a situation that has worsened this year. In both the city and the countryside, the power outages and prolonged uncertainty have altered basic services, economies, and daily life. Refrigerators lose their cooling power, ruining valuable food that was purchased at a high price. Businesses must close, resulting in lost revenue and productivity. Students struggle to study when their phone batteries are low, in part because they use their phones as flashlights. Some medical facilities have backup generators, but they’re not always operational due to a lack of spare parts. Internet connectivity has grown less reliable. Cuba’s Recovery Plans The Cuban administration has admitted that the situation is severe and has developed specific recovery plans . These include investing in thermal plant maintenance, adding new capacity, adding solar energy, and securing fuel supplies from abroad. However, progress is gradual and limited by the same problems that caused the crisis in the first place. To fix the thermal units, it’s imperative to bring major electricity providers, such as Guiteras and Cienfuegos, back to a state where they can operate reliably again. However, this method is akin to patching up a dam that’s falling apart. Long-term improvements are more important than just repairs, but they require resources that aren’t currently available. There are policies in place that encourage rooftop solar, which people commonly buy from other countries. Small solar parks are also being built; at the end of 2024 solar capacity reached 298 MW. Pilot projects for wind farms are underway. Angel Rodriguez uses a transformer from an old television to charge a battery in preparation for blackouts at his home in the Bahia neighborhood of Havana on 26 May 2025. Ramon Espinosa/AP But development lacks scale and speed. Large projects often struggle with financial constraints and inadequate planning. The government set a goal of deriving 37 percent of Cuba’s energy from renewable sources by 2030; so far they’ve reached only 3 percent. Cuba is actively looking to partner internationally on energy initiatives. Agreements with Russia primarily focus on modernizing existing thermal facilities and possibly constructing new ones. Mexico and other allies have also helped by sending fuel supplies. Talks with potential investors for green projects are moving forward, but the investment climate is quite tricky because of Cuba’s economic model and crisis, its history of defaults on payments to foreign companies, and U.S. sanctions. In partnership with China, Cuba is building up to 2,000 MW of solar capacity over more than 92 solar parks across the country. China already sent Cuba equipment for more than 100 MW of solar capacity through a different program. By January 2026, about 1,100 MW of this new capacity is expected to be operational, according to the Cuban government. As the primary power grid fails, Cubans with resources are taking matters into their own hands, often in desperate ways. Businesses, hospitals, and wealthy families are installing gasoline and solar generators; the incessant noise from which has become part of the city’s soundscape. Some communities are working together to install solar and battery systems. For example, a farmers’ cooperative in Artemisa powers its processing and irrigation facilities this way. These examples show a critical, bottom-up change, but they’re few and far between because of prohibitive upfront costs. Cuba’s people are suffering because the energy system is being pushed too far. And the comprehensive changes required for genuine, long-term recovery are currently beyond the island’s capabilities. The lights came back on after each major blackout, but the specter of the next one looms constantly.",
    "published": "Tue, 01 Jul 2025 12:00:05 +0000",
    "author": "Ricardo Torres",
    "topic": "energy",
    "collected_at": "2025-10-08T14:03:17"
  }
]